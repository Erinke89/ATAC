{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  jQuery(document).ready(function($) {\n",
    "\n",
    "  $(window).load(function(){\n",
    "    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "  });\n",
    "\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<style type=\"text/css\">\n",
    "  div#preloader { position: fixed;\n",
    "      left: 0;\n",
    "      top: 0;\n",
    "      z-index: 999;\n",
    "      width: 100%;\n",
    "      height: 100%;\n",
    "      overflow: visible;\n",
    "      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center;\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<div id=\"preloader\"></div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load rpy2 magic\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# to switch off warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# make default cell width 85% of available screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "\n",
    "# show multiple tables in python shells\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# load R libraries & functions\n",
    "%R options(warn=-1)\n",
    "%R library(RColorBrewer)\n",
    "%R library(ggplot2)\n",
    "%R library(gplots)\n",
    "%R library(gridExtra)\n",
    "%R library(ggrepel)\n",
    "    \n",
    "# load python modules\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import rpy2.robjects as robjects\n",
    "import CGAT.Database as DB\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "db = \"./csvdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MEME-ChIP Report**\n",
    "***\n",
    "## **FIMO**\n",
    "-  Searches sequences for individual matches to motifs\n",
    "    -  Input motifs are those discovered by MEME & DREME\n",
    "- Results from **FIMO, MEME, & DREME** are aggregated here\n",
    "    - All results have corrected p-values < 0.05\n",
    "    - Only MEME & DREME motifs also found by FIMO are included in this report\n",
    "- No. of FIMO matches to motifs are counted, q-values and scores for each motif are averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# R functions\n",
    "theme_notebook <- function(base_size=18, base_family=\"helvetica\") {\n",
    "                  (theme_set(theme_minimal(base_size=18))\n",
    "                  + theme(plot.title = element_text(face=\"bold\", size=20, hjust=0.5),\n",
    "                             text = element_text(),\n",
    "                             axis.title = element_text(face=\"bold\",size = rel(1)),\n",
    "                             axis.title.y = element_text(angle=90,vjust=2, size=20),\n",
    "                             axis.title.x = element_text(vjust=-0.2, size=20),\n",
    "                             axis.text = element_text(size=20),\n",
    "                             axis.line = element_line(colour=\"black\"),\n",
    "                             axis.ticks = element_line(),\n",
    "                             legend.key = element_rect(colour = NA),\n",
    "                             legend.key.size= unit(0.5, \"cm\"),\n",
    "                             legend.margin = unit(0.5, \"cm\"),\n",
    "                             legend.text = element_text(size=14),\n",
    "                             legend.title = element_text(size=16),\n",
    "                             strip.text = element_text(size=18)\n",
    "                             ))\n",
    "}\n",
    "\n",
    "# Set ggplot theme\n",
    "theme_set(theme_notebook(base_size=18))\n",
    "Palette <- c(\"#E69F00\", \"#0072B2\", \"#D55E00\", \"#009E73\", \"#56B4E9\",  \"#999999\", \"#F0E442\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_lookup(db):\n",
    "    \n",
    "    with open(\"./pipeline.ini\", \"r\") as o:\n",
    "        for line in o:\n",
    "            a = re.findall(\"^motif_db=.*\", line)\n",
    "            if len(a) > 0:\n",
    "                dbs = a[0].split(\",\")\n",
    "\n",
    "    df1 = {}\n",
    "    df2 = {}\n",
    "    df3 = {}\n",
    "    \n",
    "    transfac = [x for x in dbs if \"transfac\" in x]\n",
    "    jaspar = [x for x in dbs if \"JASPAR\" in x]\n",
    "    uniprobe = [x for x in dbs if \"uniprobe\" in x]\n",
    "    hocomoco = [x for x in dbs if \"HOCOMOCO\" in x]\n",
    "    chen = [x for x in dbs if \"chen\" in x]\n",
    "\n",
    "    n = 0\n",
    "    for i in [transfac, jaspar, uniprobe]:\n",
    "        n = n + 1\n",
    "        if n == 1:\n",
    "            db_name = \"transfac\"\n",
    "        if n == 2:\n",
    "            db_name = \"jaspar\"\n",
    "        if n == 3:\n",
    "            db_name = \"uniprobe\"\n",
    "        meme = ''.join(i).lstrip(\"motif_db=\")\n",
    "        with open(meme, \"r\") as o:\n",
    "            for line in o:\n",
    "                motif = re.findall(\"^MOTIF.*\", line)\n",
    "                if len(motif) > 0: \n",
    "                    motif = motif[0].split(\" \")\n",
    "                    motif_id = motif[1]\n",
    "                    motif_name = motif[2]\n",
    "                    df1[motif_name] = motif_id\n",
    "\n",
    "        if n == 1:\n",
    "            dfs = pd.DataFrame.from_dict(df1, orient=\"index\")\n",
    "            dfs.columns = [\"motif_id\"]\n",
    "            dfs[\"motif_name\"] = dfs.index.values\n",
    "            dfs.reset_index(inplace=True, drop=True)\n",
    "            dfs[\"database\"] = db_name\n",
    "        else:\n",
    "            dfs1 = pd.DataFrame.from_dict(df1, orient=\"index\")\n",
    "            dfs1.columns = [\"motif_id\"]\n",
    "            dfs1[\"motif_name\"] = dfs1.index.values\n",
    "            dfs1.reset_index(inplace=True, drop=True)\n",
    "            dfs1[\"database\"] = db_name\n",
    "            \n",
    "            dfs = dfs.append(dfs1)\n",
    "\n",
    "    if len(hocomoco) > 0:\n",
    "        meme = ''.join(hocomoco).lstrip(\"motif_db=\")\n",
    "        with open(meme, \"r\") as o:\n",
    "            for line in o:\n",
    "                motif = re.findall(\"^MOTIF.*\", line)\n",
    "                if len(motif) > 0: \n",
    "                    motif = motif[0].split(\".\")\n",
    "                    motif[0].split(\".\")\n",
    "                    motif_name = str(motif[0]).replace(\"MOTIF \", \"\")\n",
    "                    motif_suffix = '.'.join(motif[1:3])\n",
    "                    motif_id = '.'.join([motif_name, motif_suffix])\n",
    "                    df2[motif_name] = motif_id\n",
    "\n",
    "        df2 = pd.DataFrame.from_dict(df2, orient=\"index\")\n",
    "        df2.columns = [\"motif_id\"]\n",
    "        df2[\"motif_name\"] = df2.index.values\n",
    "        df2.reset_index(inplace=True, drop=True)\n",
    "        df2[\"database\"] = \"hocomoco\"\n",
    "    \n",
    "    if len(chen) > 0:\n",
    "        meme = ''.join(chen).lstrip(\"motif_db=\")\n",
    "        with open(meme, \"r\") as o:\n",
    "            for line in o:\n",
    "                motif = re.findall(\"^MOTIF.*\", line)\n",
    "                if len(motif) > 0: \n",
    "                    motif = motif[0].split(\" \")\n",
    "                    motif_id = motif[1]\n",
    "                    motif_name = motif[1]\n",
    "                    df3[motif_name] = motif_id\n",
    "                \n",
    "        df3 = pd.DataFrame.from_dict(df3, orient=\"index\")\n",
    "        df3.columns = [\"motif_id\"]\n",
    "        df3[\"motif_name\"] = df3.index.values\n",
    "        df3.reset_index(inplace=True, drop=True)\n",
    "        df3[\"database\"] = \"chen\"\n",
    "    \n",
    "    # merge all dfs\n",
    "    df = dfs.append([df2, df3])\n",
    "    \n",
    "    # add table to db\n",
    "    connect = sqlite3.connect(db)\n",
    "    df.to_sql(\"motif_table\", connect, if_exists=\"replace\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = motif_lookup(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meme_summary(db, conditions=\"\", widths=\"\", no_peaks=\"\", samples=\"\"):\n",
    "    beds = glob.glob(\"data.dir/*_meme.bed\")\n",
    "\n",
    "    if len(samples)==0:\n",
    "        names = []\n",
    "        for bed in beds:\n",
    "            name = os.path.basename(bed).split(\"_\")[0]\n",
    "            names.append(name)\n",
    "    else:\n",
    "        names = samples\n",
    "\n",
    "    # get meme-chip run params from pipeline.ini\n",
    "    with open(\"./pipeline.ini\", \"r\") as o:\n",
    "        for line in o:\n",
    "            if len(widths)==0:\n",
    "                w = re.findall(\"^widths=.*\", line)\n",
    "                if len(w) > 0:\n",
    "                    widths = w[0].lstrip(\"widths=\").split(\",\")\n",
    "\n",
    "\n",
    "            if len(no_peaks)==0:\n",
    "                n = re.findall(\"^npeaks=.*\", line)\n",
    "                if len(n) > 0:\n",
    "                    no_peaks = n[0].lstrip(\"npeaks=\").split(\",\")\n",
    "\n",
    "            m = re.findall(\"^nmotif=.*\", line)\n",
    "            if len(m) > 0:\n",
    "                m = m[0].lstrip(\"nmotif=\")\n",
    "                no_motifs = range(1, int(m)+1)\n",
    "\n",
    "    dfs = []\n",
    "    for name in names:\n",
    "        for c in conditions:\n",
    "            for peaks in no_peaks:\n",
    "                for width in widths:\n",
    "                    table = '_'.join([name, c, str(peaks), str(width)]) + \"_Meme_tomtom\"\n",
    "                    \n",
    "                    # get corresponding meme e_values for discovered motifs from meme.txt\n",
    "                    meme_out = \"meme.chip.dir/\" + '_'.join([name, c]) + \".\" + '.'.join([str(peaks), str(width)]) + \"/meme_out/meme.txt\"\n",
    "                    n = 0\n",
    "                    with open(meme_out, \"r\") as open_meme:\n",
    "                        for line in open_meme:\n",
    "                            motif = re.findall(\"^MOTIF.*\", line)\n",
    "                            if len(motif) > 0:\n",
    "                                n = n + 1\n",
    "                                nmotif = str(motif[0].split(\" \")[0:3][-1])\n",
    "                            e_val = re.findall(\"E-value.*\", str(motif))\n",
    "                            if len(e_val) > 0:\n",
    "                                e_value = e_val[0].split(\" \")[-1].replace(\"'\", \"\").strip(\"]\")\n",
    "\n",
    "                            if (len(e_val)>0) & (len(motif) > 0):\n",
    "                                df = pd.DataFrame([nmotif, e_value]).transpose()\n",
    "                                df.columns = [\"query_id\", \"meme_evalue\"]\n",
    "                                df[\"run\"] = str(table).rstrip(\"_Meme_tomtom\")\n",
    "                                dfs.append(df)\n",
    "    c = 0\n",
    "    for df in dfs:\n",
    "        c = c + 1\n",
    "        if c ==1:\n",
    "            motifs = df\n",
    "        else:\n",
    "            motifs = motifs.append(df)\n",
    "\n",
    "    motifs = motifs.drop_duplicates()\n",
    "    \n",
    "    # add table to db\n",
    "    connect = sqlite3.connect(db)\n",
    "    df.to_sql(\"meme_motifs\", connect, if_exists=\"replace\", index=False)\n",
    "                    \n",
    "    return motifs\n",
    "\n",
    "meme = meme_summary(db, conditions=[\"increase\", \"decrease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def memechip_summary(db, conditions=\"\", widths=\"\", no_peaks=\"\", samples=\"\"):\n",
    "    beds = glob.glob(\"data.dir/*_meme.bed\")\n",
    "\n",
    "    if len(samples)==0:\n",
    "        names = []\n",
    "        for bed in beds:\n",
    "            name = os.path.basename(bed).split(\"_\")[0]\n",
    "            names.append(name)\n",
    "    else:\n",
    "        names = samples\n",
    "\n",
    "    # get meme-chip run params from pipeline.ini\n",
    "    with open(\"./pipeline.ini\", \"r\") as o:\n",
    "        for line in o:\n",
    "            if len(widths)==0:\n",
    "                w = re.findall(\"^widths=.*\", line)\n",
    "                if len(w) > 0:\n",
    "                    widths = w[0].lstrip(\"widths=\").split(\",\")\n",
    "\n",
    "            if len(no_peaks)==0:\n",
    "                n = re.findall(\"^npeaks=.*\", line)\n",
    "                if len(n) > 0:\n",
    "                    no_peaks = n[0].lstrip(\"npeaks=\").split(\",\")\n",
    "\n",
    "            m = re.findall(\"^nmotif=.*\", line)\n",
    "            if len(m) > 0:\n",
    "                m = m[0].lstrip(\"nmotif=\")\n",
    "                no_motifs = range(1, int(m)+1)\n",
    "\n",
    "    # get existing tables in db\n",
    "    dbhandle = sqlite3.connect(db)\n",
    "    cc = dbhandle.cursor()\n",
    "    cc.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tabs = cc.fetchall()\n",
    "    tables = pd.DataFrame(tabs, columns=[\"tables\"])\n",
    "\n",
    "    dfs = []\n",
    "    for name in names:\n",
    "        for c in conditions:\n",
    "            for peaks in no_peaks:\n",
    "                for width in widths:\n",
    "                    table = '_'.join([name, c, str(peaks), str(width)]) + \"_Meme_tomtom\"\n",
    "\n",
    "                    if tables[\"tables\"].str.contains(table).any():\n",
    "\n",
    "                        n = 0\n",
    "                        for query in no_motifs:\n",
    "                            n = n + 1\n",
    "                            statement = '''select a.query_id, a.query_consensus, a.target_id, \n",
    "                                        b.motif_name, b.database, a.e_value as tomtom_evalue, a.orientation\n",
    "                                        from %(table)s a, motif_table b where a.target_id = b.motif_id \n",
    "                                        and a.query_id = %(query)s \n",
    "                                        order by e_value asc''' % locals()\n",
    "\n",
    "                            df = DB.fetch_DataFrame(statement, db)\n",
    "                            df = df.drop_duplicates()\n",
    "                            df[\"run\"] = str(table).rstrip(\"_Meme_tomtom\")\n",
    "                            df[\"DESeq2_comparison\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[0])\n",
    "                            df[\"condition\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[1])\n",
    "                            df[\"no_peaks\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[2])\n",
    "                            df[\"window\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[3])\n",
    "\n",
    "                            if n == 1:\n",
    "                                result = df\n",
    "                            else:\n",
    "                                result = result.append(df)\n",
    "\n",
    "                        dfs.append(result)\n",
    "                        \n",
    "    c = 0\n",
    "    for df in dfs:\n",
    "        c = c + 1\n",
    "        if c == 1:\n",
    "            motifs = df\n",
    "        else:\n",
    "            motifs = motifs.append(df)\n",
    "            \n",
    "    motifs[\"motif_name\"] = motifs[\"motif_name\"].apply(lambda x: x.replace(\"_MOUSE\", \"\"))\n",
    "    \n",
    "    return motifs\n",
    "\n",
    "meme_motifs = memechip_summary(db, conditions=[\"increase\", \"decrease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_meme(motifs, meme):\n",
    "\n",
    "    # annotate dfs for merging\n",
    "    motifs[\"merge\"] = motifs.apply(lambda x: '_'.join([x.run, str(x.query_id)]), axis=1)\n",
    "    meme[\"merge\"] = meme.apply(lambda x: '_'.join([x.run, str(x.query_id)]), axis=1)\n",
    "\n",
    "    meme.drop([\"query_id\", \"run\"], axis=1, inplace=True) # drop extra cols\n",
    "\n",
    "    # merge dfs\n",
    "    meme_chip = pd.merge(meme, motifs, how=\"inner\", on=\"merge\")\n",
    "    meme_chip.drop_duplicates(inplace=True)\n",
    "\n",
    "    meme_chip[\"meme_evalue\"] = meme_chip[\"meme_evalue\"].apply(lambda x: float(x)) # correct type\n",
    "    meme_chip[\"settings\"] = meme_chip[\"no_peaks\"] + \"_\" + meme_chip[\"window\"] # make column for plot annotations\n",
    "\n",
    "    # subset on sig motifs & sig matches\n",
    "    meme_chip = meme_chip[(meme_chip.tomtom_evalue < 0.05) & (meme_chip.meme_evalue < 0.05)].sort_values([\"meme_evalue\", \"tomtom_evalue\"], ascending=True)\n",
    "\n",
    "    return meme_chip\n",
    "\n",
    "meme_chip = analyse_meme(meme_motifs, meme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dreme_summary(db, conditions=\"\", widths=\"\", no_peaks=\"\", samples=\"\"):\n",
    "\n",
    "    beds = glob.glob(\"data.dir/*_meme.bed\")\n",
    "\n",
    "    names = []\n",
    "    for bed in beds:\n",
    "        name = os.path.basename(bed).split(\"_\")[0]\n",
    "        names.append(name)\n",
    "\n",
    "    # get meme-chip run params from pipeline.ini\n",
    "    with open(\"./pipeline.ini\", \"r\") as o:\n",
    "        for line in o:\n",
    "            if len(widths)==0:\n",
    "                w = re.findall(\"^widths=.*\", line)\n",
    "                if len(w) > 0:\n",
    "                    widths = w[0].lstrip(\"widths=\").split(\",\")\n",
    "\n",
    "            if len(no_peaks)==0:\n",
    "                n = re.findall(\"^npeaks=.*\", line)\n",
    "                if len(n) > 0:\n",
    "                    no_peaks = n[0].lstrip(\"npeaks=\").split(\",\")\n",
    "\n",
    "    df = []\n",
    "    n = 0\n",
    "    for name in names:\n",
    "        for c in conditions:\n",
    "            for peaks in no_peaks:\n",
    "                for width in widths:\n",
    "                    table = '_'.join([name, c, str(peaks), str(width)]) + \"_Dreme_tomtom\"\n",
    "\n",
    "\n",
    "                    # get corresponding meme e_values for discovered motifs from meme.txt\n",
    "                    meme_out = \"meme.chip.dir/\" + '_'.join([name, c]) + \".\" + '.'.join([str(peaks), str(width)]) + \"/dreme_out/dreme.txt\"\n",
    "\n",
    "                    with open(meme_out, \"r\") as open_meme:\n",
    "                        l = 0\n",
    "                        for line in open_meme:\n",
    "                            motif = re.findall(\"^#.*\", line)\n",
    "                            if len(motif) > 0:\n",
    "                                l = l + 1\n",
    "                                if l > 6:\n",
    "                                    motif =  [ x for x in motif if \"Stopping\" not in x]\n",
    "                                    motif =  [ x for x in motif if \"Running\" not in x]\n",
    "                                    motif =  [ x for x in motif if \"Word\" not in x]\n",
    "                                    if len(motif) > 0:\n",
    "                                        motif = [x for x in ''.join(motif).split() if x not in [\"BEST\", \"#\"]]\n",
    "                                        motif.append(table.replace(\"_Dreme_tomtom\", \"\"))\n",
    "                                        df.append(motif)\n",
    "\n",
    "    df = pd.DataFrame(df, columns = [\"motif\", \"motif_rc\", \"pos\", \"neg\", \"p_value\", \"dreme_evalue\", \"run\"])\n",
    "    df.drop(\"p_value\", inplace=True, axis=1)\n",
    "#     df = df.drop_duplicates()\n",
    "\n",
    "    # add table to db\n",
    "    connect = sqlite3.connect(db)\n",
    "    df.to_sql(\"dreme_motifs\", connect, if_exists=\"replace\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "dreme = dreme_summary(db, conditions=[\"increase\", \"decrease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dremechip_summary(db, conditions=\"\", widths=\"\", no_peaks=\"\", samples=\"\"):\n",
    "    beds = glob.glob(\"data.dir/*_meme.bed\")\n",
    "\n",
    "    if len(samples)==0:\n",
    "        names = []\n",
    "        for bed in beds:\n",
    "            name = os.path.basename(bed).split(\"_\")[0]\n",
    "            names.append(name)\n",
    "    else:\n",
    "        names = samples\n",
    "\n",
    "    # get meme-chip run params from pipeline.ini\n",
    "    with open(\"./pipeline.ini\", \"r\") as o:\n",
    "        for line in o:\n",
    "            if len(widths)==0:\n",
    "                w = re.findall(\"^widths=.*\", line)\n",
    "                if len(w) > 0:\n",
    "                    widths = w[0].lstrip(\"widths=\").split(\",\")\n",
    "\n",
    "            if len(no_peaks)==0:\n",
    "                n = re.findall(\"^npeaks=.*\", line)\n",
    "                if len(n) > 0:\n",
    "                    no_peaks = n[0].lstrip(\"npeaks=\").split(\",\")\n",
    "\n",
    "    # get existing tables in db\n",
    "    dbhandle = sqlite3.connect(db)\n",
    "    cc = dbhandle.cursor()\n",
    "    cc.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tabs = cc.fetchall()\n",
    "    tables = pd.DataFrame(tabs, columns=[\"tables\"])\n",
    "\n",
    "    dfs = []\n",
    "    for name in names:\n",
    "        for c in conditions:\n",
    "            for peaks in no_peaks:\n",
    "                for width in widths:\n",
    "                    table = '_'.join([name, c, str(peaks), str(width)]) + \"_Dreme_tomtom\"\n",
    "\n",
    "                    if tables[\"tables\"].str.contains(table).any():\n",
    "\n",
    "                        statement = '''select a.query_id, a.query_consensus, a.target_id, \n",
    "                                    b.motif_name, b.database, a.e_value as tomtom_evalue, a.orientation\n",
    "                                    from %(table)s a, motif_table b where a.target_id = b.motif_id \n",
    "                                    order by e_value asc''' % locals()\n",
    "\n",
    "                        df = DB.fetch_DataFrame(statement, db)\n",
    "                        df = df.drop_duplicates()\n",
    "                        df[\"run\"] = str(table).rstrip(\"_Dreme_tomtom\")\n",
    "                        df[\"DESeq2_comparison\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[0])\n",
    "                        df[\"condition\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[1])\n",
    "                        df[\"no_peaks\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[2])\n",
    "                        df[\"window\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[3])\n",
    "\n",
    "                        dfs.append(df)\n",
    "\n",
    "    c = 0\n",
    "    for df in dfs:\n",
    "        c = c + 1\n",
    "        if c == 1:\n",
    "            motifs = df\n",
    "        else:\n",
    "            motifs = motifs.append(df)\n",
    "        motifs.head()\n",
    "            \n",
    "    motifs[\"motif_name\"] = motifs[\"motif_name\"].apply(lambda x: x.replace(\"_MOUSE\", \"\"))\n",
    "    \n",
    "    return motifs\n",
    "\n",
    "dreme_motifs = dremechip_summary(db, conditions=[\"increase\", \"decrease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_dreme(motifs, dreme):\n",
    "\n",
    "    # reformat dfs for merge\n",
    "    motifs.rename(columns={\"query_id\":\"motif\"}, inplace=True)\n",
    "\n",
    "    # merge dfs\n",
    "    dreme_chip = pd.merge(dreme, motifs, how=\"inner\", on=[\"run\", \"motif\"])\n",
    "    dreme_chip.drop_duplicates(inplace=True)\n",
    "\n",
    "    dreme_chip[\"dreme_evalue\"] = dreme_chip[\"dreme_evalue\"].apply(lambda x: float(x)) # correct type\n",
    "    dreme_chip[\"settings\"] = dreme_chip[\"no_peaks\"] + \"_\" + dreme_chip[\"window\"] # make column for plot annotations\n",
    "\n",
    "    # subset on sig motifs & sig matches\n",
    "    dreme_chip = dreme_chip[(dreme_chip.tomtom_evalue < 0.05) & (dreme_chip.dreme_evalue < 0.05)].sort_values([\"dreme_evalue\", \"tomtom_evalue\"], ascending=True)\n",
    "\n",
    "    return dreme_chip\n",
    "\n",
    "dreme_chip = analyse_dreme(dreme_motifs, dreme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fimo_summary(db, conditions=\"\", widths=\"\", no_peaks=\"\", samples=\"\"):\n",
    "    beds = glob.glob(\"data.dir/*_meme.bed\")\n",
    "\n",
    "    names = []\n",
    "    for bed in beds:\n",
    "        name = os.path.basename(bed).split(\"_\")[0]\n",
    "        names.append(name)\n",
    "\n",
    "    # get meme-chip run params from pipeline.ini\n",
    "    with open(\"./pipeline.ini\", \"r\") as o:\n",
    "        for line in o:\n",
    "            if len(widths)==0:\n",
    "                w = re.findall(\"^widths=.*\", line)\n",
    "                if len(w) > 0:\n",
    "                    widths = w[0].lstrip(\"widths=\").split(\",\")\n",
    "\n",
    "            if len(no_peaks)==0:\n",
    "                n = re.findall(\"^npeaks=.*\", line)\n",
    "                if len(n) > 0:\n",
    "                    no_peaks = n[0].lstrip(\"npeaks=\").split(\",\")\n",
    "\n",
    "    # get existing tables in db\n",
    "    dbhandle = sqlite3.connect(db)\n",
    "    cc = dbhandle.cursor()\n",
    "    cc.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "    tabs = cc.fetchall()\n",
    "    tables = pd.DataFrame(tabs, columns=[\"tables\"])\n",
    "\n",
    "    dfs = []\n",
    "    for name in names:\n",
    "        for c in conditions:\n",
    "            for peaks in no_peaks:\n",
    "                for width in widths:\n",
    "                    fimo = '_'.join([name, c, str(peaks), str(width)]) + \"_fimo_summary\"\n",
    "\n",
    "                    if tables[\"tables\"].str.contains(fimo).any():\n",
    "                            statement = '''select matched_sequence as query_consensus, pattern_name as motif, q_value as fimo_qvalue, \n",
    "                                            score as fimo_score, sequence_name, start, stop, strand as orientation\n",
    "                                            from %(fimo)s where q_value < 0.05 order by q_value asc''' % locals()\n",
    "\n",
    "                            df = DB.fetch_DataFrame(statement, db)\n",
    "                            df[\"run\"] = str(fimo).rstrip(\"_fimo_summary\")\n",
    "                            df[\"DESeq2_comparison\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[0])\n",
    "                            df[\"condition\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[1])\n",
    "                            df[\"no_peaks\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[2])\n",
    "                            df[\"window\"] = df[\"run\"].apply(lambda x: x.split(\"_\")[3])\n",
    "\n",
    "                            dfs.append(df)\n",
    "\n",
    "    c = 0\n",
    "    for df in dfs:\n",
    "        c = c + 1\n",
    "        if c == 1:\n",
    "            fimo = df\n",
    "        else:\n",
    "            fimo = fimo.append(df)\n",
    "            \n",
    "    return fimo\n",
    "\n",
    "fimo = fimo_summary(db, conditions=[\"increase\", \"decrease\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreme_chip_fimo = pd.merge(fimo.drop_duplicates(), dreme_chip, how=\"inner\", on=[\"run\", \"motif\", \"query_consensus\", \"orientation\", \"DESeq2_comparison\", \"condition\", \"no_peaks\", \"window\"])\n",
    "\n",
    "dreme_chip_fimo = dreme_chip_fimo.groupby([\"query_consensus\", \"motif\", \"orientation\", \"dreme_evalue\", \"tomtom_evalue\", \n",
    "                        \"target_id\", \"motif_name\", \"database\", \"DESeq2_comparison\", \"condition\", \"run\", \n",
    "                         \"settings\"]).agg({\"fimo_qvalue\":\"mean\", \"fimo_score\":\"mean\", \"sequence_name\":\"count\"})\n",
    "\n",
    "dreme_chip_fimo.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meme_chip_fimo = pd.merge(fimo.drop_duplicates(), meme_chip.rename(columns={\"query_id\":\"motif\"}), how=\"inner\", on=[\"run\", \"motif\", \"query_consensus\", \"orientation\", \"DESeq2_comparison\", \"condition\", \"no_peaks\", \"window\"])\n",
    "\n",
    "meme_chip_fimo = meme_chip_fimo.groupby([\"query_consensus\", \"motif\", \"orientation\", \"meme_evalue\", \"tomtom_evalue\", \n",
    "                        \"target_id\", \"motif_name\", \"database\", \"DESeq2_comparison\", \"condition\", \"run\", \n",
    "                         \"settings\"]).agg({\"fimo_qvalue\":\"mean\", \"fimo_score\":\"mean\", \"sequence_name\":\"count\"})\n",
    "\n",
    "meme_chip_fimo.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dreme_chip_fimo[\"motif_discovery\"] = \"DREME\"\n",
    "dreme_chip_fimo.rename(columns={\"dreme_evalue\":\"motif_discovery_evalue\"}, inplace=True)\n",
    "\n",
    "meme_chip_fimo[\"motif_discovery\"] = \"MEME\"\n",
    "meme_chip_fimo.rename(columns={\"meme_evalue\":\"motif_discovery_evalue\"}, inplace=True)\n",
    "\n",
    "fimo_chip = dreme_chip_fimo.append(meme_chip_fimo)\n",
    "fimo_chip.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make extra cols for annotation\n",
    "fimo_chip[\"width\"] = fimo_chip[\"settings\"].apply(lambda x: \"width_\" + x.split(\"_\")[1])\n",
    "fimo_chip[\"peaks\"] = fimo_chip[\"settings\"].apply(lambda x: \"npeaks_\" + x.split(\"_\")[0])\n",
    "# fimo_chip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i fimo_chip -w 1200 -h 1200\n",
    "\n",
    "for (comp in unique(fimo_chip$DESeq2_comparison)){\n",
    "    df <- subset(fimo_chip, DESeq2_comparison == comp)\n",
    "\n",
    "    p <- ggplot(df, aes(y=-log10(tomtom_evalue), x=-log10(motif_discovery_evalue), colour=condition, \n",
    "                        shape=motif_discovery, alpha=-fimo_qvalue)) +\n",
    "        geom_point(aes(size=sequence_name), position=position_jitterdodge()) + \n",
    "        scale_size(range=c(2,8), name=\"No. motifs\") +\n",
    "        scale_alpha(range=c(0.3,1)) +\n",
    "        geom_text_repel(data=df[-log10(df$tomtom_evalue) > \n",
    "                                       quantile(-log10(df$tomtom_evalue), 0.9, na.rm=T), ], \n",
    "                        aes(y=-log10(tomtom_evalue), x=-log10(motif_discovery_evalue), label=motif_name), colour=\"black\", alpha=1) +\n",
    "        facet_grid(width ~ peaks) +\n",
    "        theme(legend.position=\"bottom\", legend.direction=\"horizontal\") +\n",
    "        scale_colour_manual(values=Palette) +\n",
    "        guides(color=guide_legend(override.aes=list(size=6))) +\n",
    "        guides(alpha=guide_legend(override.aes=list(size=6)))  +\n",
    "        guides(shape=guide_legend(override.aes=list(size=6)))  +\n",
    "        labs(title=comp)\n",
    "    \n",
    "    grid.arrange(p, ncol=1, nrow=1)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Motif Tables:\n",
    "* sorted by peak size & fimo q-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peaks with increased accessibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fimo_chip[\"DESeq2_comparison\"].unique():\n",
    "    print i\n",
    "    fimo_chip[(fimo_chip.DESeq2_comparison == i) & (fimo_chip.condition == \"increase\")].sort_values([\"width\", \"fimo_qvalue\"], ascending=True).drop_duplicates([\"target_id\", \"motif_name\", \"orientation\"], keep=\"first\").head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peaks with decreased accessibility:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fimo_chip[\"DESeq2_comparison\"].unique():\n",
    "    print i\n",
    "    fimo_chip[(fimo_chip.DESeq2_comparison == i) & (fimo_chip.condition == \"decrease\")].sort_values([\"width\", \"fimo_qvalue\"], ascending=True).drop_duplicates([\"target_id\", \"motif_name\", \"orientation\"], keep=\"first\").head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
