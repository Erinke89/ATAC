{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  jQuery(document).ready(function($) {\n",
    "\n",
    "  $(window).load(function(){\n",
    "    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "  });\n",
    "\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<style type=\"text/css\">\n",
    "  div#preloader { position: fixed;\n",
    "      left: 0;\n",
    "      top: 0;\n",
    "      z-index: 999;\n",
    "      width: 100%;\n",
    "      height: 100%;\n",
    "      overflow: visible;\n",
    "      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center;\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<div id=\"preloader\"></div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ~/devel/my_scripts/Jupyter/init.ipy\n",
    "\n",
    "# load R libraries & functions\n",
    "%R library(RColorBrewer)\n",
    "%R source(\"/gfs/devel/tkhoyratty/my_scripts/R/pca.R\")\n",
    "\n",
    "# load python functions\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sys.path.insert(0, \"/gfs/devel/tkhoyratty/my_scripts/python/\")\n",
    "from upperQuantileNorm import upperQuantileNorm\n",
    "\n",
    "db = \"/gfs/work/tkhoyratty/AirPouch_ATAC/analysis/atac_pipeline_trim/csvdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATAC Pipeline Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import counts & upper quantile normalise\n",
    "def get_counts(statement, filt=\"all_fragments\"):\n",
    "    # get df, filter on fragment size\n",
    "    \n",
    "    df = DB.fetch_DataFrame(statement, db)\n",
    "\n",
    "    df = df.pivot(\"sample_id\", \"peak_id\", \"RPM\").transpose()\n",
    "    df.index.name = None\n",
    "\n",
    "    df = upperQuantileNorm(df) # normalise to upper quantiles for between sample comparison\n",
    "    df[\"size_filt\"] = filt\n",
    "    \n",
    "    return df\n",
    "\n",
    "statement = '''select sample_id, peak_id, RPM_width_norm *1000 as RPM \n",
    "                                   from all_norm_counts where size_filt == \"all_fragments\" '''\n",
    "counts = get_counts(statement)\n",
    "counts = counts.append(get_counts(statement, filt=\"<150bp\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get sample information\n",
    "sample_info = DB.fetch_DataFrame('''select * from sample_info''', db)\n",
    "sample_info[\"replicate\"] = sample_info[\"replicate\"].apply(lambda x: str(x))\n",
    "sample_info.index = sample_info[\"sample_id\"]\n",
    "sample_info.index.name = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapping QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_stats(paired=True, db=db, sample_info=sample_info):\n",
    "    '''Collect all mapping stats & retrun df for plotting'''\n",
    "    \n",
    "    if paired==True:\n",
    "        reads = DB.fetch_DataFrame('''select READS_ALIGNED_IN_PAIRS/2 as MAPPED_PAIRS, PCT_READS_ALIGNED_IN_PAIRS, \n",
    "                                      TOTAL_READS, PCT_ADAPTER, sample_id from picardAlignmentSummary \n",
    "                                      where CATEGORY = \"PAIR\" ''', db)\n",
    "    if paired==False:\n",
    "        print \"Update function for non-paired data\"\n",
    "    \n",
    "    # Format mapping qc df\n",
    "    reads[\"Filter\"] = reads[\"sample_id\"].apply(lambda x: x.split(\".\")[-1])\n",
    "    reads[\"Filter\"] = reads[\"sample_id\"].apply(lambda x: x.split(\"_\")[-1] if \"size_filt_prep\" not in x else \"prep<150bp\")\n",
    "    reads[\"sample_id\"] = reads[\"sample_id\"].apply(lambda x: '_'.join(x.split(\"_\")[0:-1]))\n",
    "    reads[\"sample_id\"] = reads[\"sample_id\"].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "    if len(sample_info)==0:\n",
    "        print \"Provide sample_info df with sample annotations\"\n",
    "        \n",
    "    reads = pd.merge(reads, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "    \n",
    "    # get no. reads mapping to chrM\n",
    "    chrm = DB.fetch_DataFrame('''select * from allContig''', db)\n",
    "    \n",
    "    # reformat df\n",
    "    chrm = chrm.pivot(\"sample_id\", \"contig\", \"mapped_reads\")\n",
    "    chrm[\"total_mapped_reads\"] = chrm.sum(axis=1)\n",
    "    chrm[\"sample_id\"] = chrm.index.values\n",
    "    chrm.index.name = None\n",
    "    chrm = chrm[[\"chrM\", \"total_mapped_reads\", \"sample_id\"]]\n",
    "    chrm[\"pct_chrM\"] = chrm[\"chrM\"] / chrm[\"total_mapped_reads\"] *100 # % reads mapping to chrM\n",
    "\n",
    "    # annotate df\n",
    "    chrm[\"sample_id\"] = chrm[\"sample_id\"].apply(lambda x: str(x).split(\".\")[0])\n",
    "    chrm = pd.merge(chrm, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "    chrm[\"Filter\"] = \"genome\" # chrM only in genomic reads as filtered out after, others not tested\n",
    "\n",
    "    df = pd.merge(reads, chrm[[\"pct_chrM\", \"sample_id\", \"Filter\"]], how=\"outer\", on=[\"sample_id\", \"Filter\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "mapping_qc = mapping_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%R -i mapping_qc -w 800 -h 600\n",
    "\n",
    "Palette <- c(\"#E69F00\", \"#0072B2\", \"#D55E00\", \"#009E73\",  \"#56B4E9\",  \"#999999\", \"#F0E442\")\n",
    "\n",
    "get_legend <- function(a.gplot){ \n",
    "  tmp <- ggplot_gtable(ggplot_build(a.gplot)) \n",
    "  leg <- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\") \n",
    "  legend <- tmp$grobs[[leg]] \n",
    "  return(legend)} \n",
    "\n",
    "test <- ggplot(mapping_qc, aes(y=MAPPED_PAIRS, x=sample_id, colour=condition, shape=Filter)) + \n",
    "        geom_point(size=6) + \n",
    "        theme_Publication()\n",
    "        \n",
    "a <- ggplot(mapping_qc, aes(y=MAPPED_PAIRS, x=sample_id, colour=condition, shape=Filter)) + \n",
    "        geom_point(size=6) + \n",
    "        theme_Publication() + \n",
    "        theme(axis.text.x=element_blank()) +\n",
    "        scale_y_continuous(limits=c(0, 65000000)) +\n",
    "        scale_colour_manual(values=Palette) +\n",
    "        labs(x=\"\", y=\"Mapped Pairs\") +\n",
    "        geom_hline(yintercept=25000000, lty=\"dashed\", col=\"black\")\n",
    "\n",
    "b <- ggplot(subset(mapping_qc, Filter==\"genome\"), \n",
    "            aes(y=PCT_READS_ALIGNED_IN_PAIRS*100, x=sample_id, colour=condition)) + \n",
    "        geom_point(size=6, shape=17) + \n",
    "        theme_Publication() + \n",
    "        theme(axis.text.x=element_blank()) +\n",
    "        labs(y=\"% Reads in Pairs\", x=\"\") +\n",
    "        scale_y_continuous(limits=c(0, 100)) +\n",
    "        scale_colour_manual(values=Palette)\n",
    "\n",
    "c <- ggplot(mapping_qc, aes(y=PCT_ADAPTER, x=sample_id, colour=condition, shape=Filter)) + \n",
    "        geom_point(size=6) + \n",
    "        theme_Publication() + \n",
    "        theme(axis.text.x=element_blank()) +\n",
    "        scale_colour_manual(values=Palette) +\n",
    "        labs(x=\"\", y=\"% Adaptor\")\n",
    "\n",
    "d <- ggplot(mapping_qc, aes(y=pct_chrM, x=sample_id, colour=condition)) + \n",
    "        geom_point(size=6, shape=17) +\n",
    "        theme_Publication() +\n",
    "        labs(x=\"\", y= \"% chrM Reads\") +\n",
    "        scale_y_continuous(limits=c(0,100)) +\n",
    "        theme(axis.text.x=element_blank()) +\n",
    "        scale_colour_manual(values=Palette)\n",
    "\n",
    "legend <- get_legend(a)\n",
    "\n",
    "grid.arrange(a + theme(legend.position=\"none\"), b + theme(legend.position=\"none\"), \n",
    "             c + theme(legend.position=\"none\"), d + theme(legend.position=\"none\"), \n",
    "             ncol=2, nrow=2, bottom=legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_stats(db=db, sample_info=sample_info):\n",
    "    '''Collect insert size stats & format df for plotting'''\n",
    "    \n",
    "    def clean(df):\n",
    "        df[\"Filter\"] = df[\"sample_id\"].apply(lambda x: x.split(\".\")[-1])\n",
    "        df[\"Filter\"] = df[\"sample_id\"].apply(lambda x: x.split(\"_\")[-1] if \"size_filt_prep\" not in x else \"prep<150bp\")\n",
    "        df[\"sample_id\"] = df[\"sample_id\"].apply(lambda x: x.rstrip(\"_prep\"))\n",
    "        df[\"sample_id\"] = df[\"sample_id\"].apply(lambda x: x.split(\".\")[0])\n",
    "        df = pd.merge(df, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "        return df\n",
    "    \n",
    "    insert_sizes = DB.fetch_DataFrame('''select * from picardInsertSizeHistogram where sample_id like \"%prep\"''', db)\n",
    "    size_stats = DB.fetch_DataFrame('''select * from picardInsertSizeMetrics where sample_id like \"%prep\"''', db)\n",
    "\n",
    "    insert_sizes = clean(insert_sizes)\n",
    "    size_stats = clean(size_stats)\n",
    "\n",
    "    return [size_stats, insert_sizes]\n",
    "\n",
    "(size_stats, insert_sizes) = fragment_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i insert_sizes,size_stats -w 1200 -h 1200\n",
    "\n",
    "a <- ggplot(insert_sizes, aes(y=All_Reads_fr_count, x=insert_size)) + \n",
    "        geom_bar(stat=\"identity\") +\n",
    "        scale_fill_manual(values=Palette) +\n",
    "        scale_x_continuous(limits=c(0, 800)) + \n",
    "        labs(y=\"No. Fragments\", x=\"Fragment length (b.p.)\") +\n",
    "        theme_Publication() + facet_wrap(~ Filter)\n",
    "\n",
    "c <- ggplot(insert_sizes, \n",
    "            aes(x=category, y=insert_size, fill=condition, alpha=factor(replicate))) + \n",
    "        geom_boxplot() +\n",
    "        scale_fill_manual(values=Palette) +\n",
    "        coord_cartesian(y=c(0, 1000)) + \n",
    "        labs(y=\"Fragment length (b.p.)\", x=\"Sample\") +\n",
    "        theme_Publication() +\n",
    "        scale_alpha_discrete(range=c(0.5,1), name=\"replicate\") +\n",
    "        theme(axis.text.x=element_blank())  + facet_wrap(~ Filter)\n",
    "\n",
    "grid.arrange(a, c, ncol=1, nrow=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Peakcalling QC\n",
    "### All peaks\n",
    "* All detected peaks with & without filtering reads by size & fraction of reads in peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_stats = DB.fetch_DataFrame('''select a.no_peaks, a.size_filt, b.FRIP, b.sample_id from no_peaks a, \n",
    "                                frip_table b where a.sample_id=b.sample_id and a.size_filt=b.size_filt ''', db)\n",
    "\n",
    "peak_stats = pd.merge(peak_stats, sample_info, how=\"inner\", on=\"sample_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i peak_stats  -w 800 -h 350\n",
    "\n",
    "no_peaks <- ggplot(peak_stats, \n",
    "                   aes(y=no_peaks, x=category, colour=condition, \n",
    "                       shape=factor(replicate), alpha=size_filt)) + \n",
    "                geom_point(size=6) + theme_Publication() +\n",
    "                theme(axis.text.x=element_blank()) + \n",
    "                scale_alpha_discrete(range=c(0.4, 1)) +\n",
    "                labs(y=\"No. Peaks\", y=\"\", x=\"\") +\n",
    "                scale_y_continuous(limits=c(0, 40000)) +\n",
    "                scale_colour_manual(values=Palette) #+ facet_wrap(~ size_filt)\n",
    "\n",
    "frip_plot <- ggplot(peak_stats, \n",
    "                    aes(y=FRIP, x=category, colour=condition, shape=factor(replicate), \n",
    "                        alpha=size_filt)) + \n",
    "                geom_point(size=6) + theme_Publication() +\n",
    "                theme(axis.text.x=element_blank()) + \n",
    "                scale_alpha_discrete(range=c(0.4, 1)) +\n",
    "                labs(y=\"FRIP\", x=\"\") +\n",
    "                scale_y_continuous(limits=c(0,1)) + \n",
    "                scale_colour_manual(values=Palette) +\n",
    "                guides(colour=guide_legend(override.aes=list(size=6)), \n",
    "                       shape=guide_legend(override.aes=list(size=6))) +\n",
    "                geom_hline(yintercept=0.2, lty=\"dashed\", colour=\"black\")  #+ facet_wrap(~ size_filt)\n",
    "\n",
    "# hc_peaks <- ggplot(hc_peaks, aes(y=no_peaks, x=sample, fill=Tissue)) + \n",
    "#                 geom_bar(stat=\"identity\") + theme_Publication() +\n",
    "#                 theme(axis.text.x=element_blank()) + \n",
    "#                 labs(y=\"No. High Conf. Peaks\", y=\"\", x=\"\") +\n",
    "#                 scale_y_continuous(limits=c(0, 40000)) +\n",
    "#                 scale_fill_manual(values=Palette)\n",
    "\n",
    "key <- get_legend(frip_plot)\n",
    "\n",
    "grid.arrange(no_peaks + theme(legend.position=\"none\"), frip_plot + theme(legend.position=\"none\"),\n",
    "             ncol=2, nrow=1, bottom=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High confidence peaks\n",
    "* Peaks which are consistent between biological replicates, from size filtered & non- size filtered peak sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_peaks = DB.fetch_DataFrame('''select * from no_peaks where merged like \"%merged\" ''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i merged_peaks -w 600 -h 400\n",
    "\n",
    "Palette <- c(\"#E69F00\", \"#0072B2\", \"#D55E00\", \"#009E73\",  \"#56B4E9\",  \"#999999\", \"#F0E442\")\n",
    "\n",
    "ggplot(merged_peaks, aes(y=no_peaks, x=sample_id, shape=size_filt, colour=sample_id)) +\n",
    "    geom_point(size=6) +\n",
    "    scale_colour_manual(values=Palette, guide=FALSE) +\n",
    "    theme_Publication() +\n",
    "    labs(x=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploration \n",
    "* based on counts over merged peakset\n",
    "* merged peakset consists of all detected peaks (not only high confidence)\n",
    "* counts are normalised for sequencing depth, peak width, and upper quantile normalised for between sample comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset counts\n",
    "all_counts = counts.loc[counts.size_filt == \"all_fragments\"]\n",
    "all_counts.drop(\"size_filt\", axis=1, inplace=True)\n",
    "\n",
    "all_counts_anno = all_counts.copy(deep=True)\n",
    "all_counts_anno.columns = sample_info[\"category\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation between nomalised counts in consensus peakset\n",
    "* clustering from Ward method & Manhattan distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i all_counts_anno\n",
    "\n",
    "cm <- data.matrix(log2(all_counts_anno +1))\n",
    "m <- cor(cm, method=\"pearson\", use=\"all\")\n",
    "\n",
    "\n",
    "library(ComplexHeatmap)\n",
    "library(circlize)\n",
    "library(dendextend)\n",
    "\n",
    "distr <- dist(m, method=\"manhattan\")\n",
    "clustr <- hclust(distr, method=\"ward.D2\")\n",
    "dendr <- as.dendrogram(clustr)\n",
    "dendr <- dendr %>% sort(type=\"labels\")\n",
    "\n",
    "distc <- dist(t(m), method=\"manhattan\")\n",
    "clustc <- hclust(distc, method=\"ward.D2\")\n",
    "dendc <- as.dendrogram(clustc)\n",
    "dendc <- rev(dendc) %>% sort(type=\"labels\")\n",
    "\n",
    "p2 <- Heatmap(m,\n",
    "       col = colorRamp2(c(min(m), max(m)), c(\"white\", \"red\")),\n",
    "       cluster_rows=dendr,\n",
    "       cluster_columns=dendc,\n",
    "       column_dend_reorder = FALSE,\n",
    "       column_dend_height = unit(2, \"cm\"),\n",
    "       row_dend_width = unit(2, \"cm\"),\n",
    "       row_names_gp=gpar(fontsize=16),\n",
    "       column_names_gp=gpar(fontsize=16),\n",
    "       name=\"Pearson Correlation:\",\n",
    "       heatmap_legend_param=list(legend_direction=\"horizontal\", \n",
    "                                  at=c(0.9, 1), \n",
    "                                  color_bar = \"continuous\",\n",
    "                                  legend_width = unit(5, \"cm\"), \n",
    "                                  title_position = \"lefttop\",\n",
    "                                  title_gp=gpar(fontsize=18),\n",
    "                                  labels_gp=gpar(fontsize=14)),\n",
    "       )\n",
    "\n",
    "draw(p2, heatmap_legend_side = \"bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -w 1200 -h 500 -i sample_info,all_counts\n",
    "\n",
    "df <- as.data.frame(log2(all_counts+1))\n",
    "# df <- t(df)\n",
    "pca <- prcomp(df, scale=F)\n",
    "\n",
    "head(pca$x)\n",
    "\n",
    "pca_plots <- ggplot_prcomp(pca, \n",
    "             plots=list(\"A\"=c(\"PC1\",\"PC2\"), \"B\"=c(\"PC3\", \"PC4\")),\n",
    "             sample_information=sample_info, \n",
    "             shape=\"replicate\", \n",
    "             color=\"condition\",\n",
    "             size=7,\n",
    "             nudge_scale_factor=30) \n",
    "\n",
    "\n",
    "a <- pca_plots$A + theme_Publication() + \n",
    "        scale_colour_manual(values=Palette, name=\"condition:\") + \n",
    "        scale_shape_manual(values=c(16,17), name=\"replicate:\") +\n",
    "        guides(colour=guide_legend(override.aes=list(size=8)), \n",
    "               shape=guide_legend(override.aes=list(size=6)))\n",
    "b <- pca_plots$B + theme_Publication() + \n",
    "        scale_colour_manual(values=Palette, name=\"condition:\") + \n",
    "        scale_shape_manual(values=c(16,17), name=\"replicate:\")\n",
    "c <- pca_plots$scree + theme_Publication()  + \n",
    "        scale_colour_manual(values=Palette, name=\"condition:\") + \n",
    "        scale_shape_manual(values=c(16,17), name=\"replicate:\")\n",
    "\n",
    "\n",
    "get_legend <- function(a.gplot){ \n",
    "  tmp <- ggplot_gtable(ggplot_build(a.gplot)) \n",
    "  leg <- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\") \n",
    "  legend <- tmp$grobs[[leg]] \n",
    "  return(legend)} \n",
    "                        \n",
    "legend <- get_legend(a)\n",
    "                      \n",
    "a <- a + theme(legend.position=c(10, 10)) # dont show legend\n",
    "b <- b + theme(legend.position=c(10, 10))\n",
    "                      \n",
    "lay = rbind(c(1,1,1,2,2,2,3,3,3), \n",
    "            c(1,1,1,2,2,2,3,3,3),\n",
    "            c(1,1,1,2,2,2,3,3,3), \n",
    "            c(1,1,1,2,2,2,3,3,3), \n",
    "            c(NA,4,4,4,NA,NA,NA,NA,NA))  \n",
    "                      \n",
    "        \n",
    "                      \n",
    "grid.arrange(top=textGrob(\"PCA of Normalised Read Counts Over All Peaks\", gp=gpar(fontfamily=\"Helvetica\", fontface=\"bold\", fontsize=23)),\n",
    "             a, b, c, legend, layout_matrix=lay)\n",
    "\n",
    "# pca_plots$A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -h 500 -w 500\n",
    "\n",
    "require(Rtsne)\n",
    "\n",
    "log2counts <- as.data.frame(log2(all_counts+1))\n",
    "                            \n",
    "tsne_out <- Rtsne(t(log2counts), pca=T, perplexity=2)\n",
    "\n",
    "tsne_df <- as.data.frame(tsne_out$Y)\n",
    "rownames(tsne_df) <- colnames(log2counts)\n",
    "colnames(tsne_df) <- c(\"tSNE1\", \"tSNE2\")\n",
    "tsne_df$sample_id <- rownames(tsne_df)\n",
    "\n",
    "tsne_df <- merge(tsne_df, sample_info, by=\"sample_id\")\n",
    "head(tsne_df)\n",
    "\n",
    "p <- ggplot(tsne_df, aes(y=tSNE1, x=tSNE2, shape=replicate, colour=condition)) + \n",
    "        geom_point(size=7) + \n",
    "        theme_Publication()  + \n",
    "        scale_colour_manual(values=Palette, name=\"condition:\") + \n",
    "        scale_shape_manual(values=c(16,17), name=\"replicate:\")\n",
    "\n",
    "grid.arrange(p, ncol=1, nrow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use sample information to get no. replicates & conditions\n",
    "rep_pairs = sample_info.pivot(\"condition\", \"replicate\", \"category\").transpose()\n",
    "rep_pairs.columns.name = None\n",
    "rep_pairs.index.name = None\n",
    "\n",
    "# report replicates to dict\n",
    "reps = {}\n",
    "for col in rep_pairs.columns:\n",
    "    reps[col]=[rep_pairs[col].iloc[0], rep_pairs[col].iloc[1]]\n",
    "    \n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")# set seaborn theme\n",
    "\n",
    "# use dict to subset df of normalised counts & plot rep correlations\n",
    "for key in reps:\n",
    "    df = all_counts_anno[reps[key]]\n",
    "    df.columns = [\"Rep1\", \"Rep2\"]\n",
    "    p = sns.jointplot(data=df, y=\"Rep1\", x=\"Rep2\", kind=\"reg\", size=7, color=\"g\")\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    p.fig.suptitle(key) # add title\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
