{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  jQuery(document).ready(function($) {\n",
    "\n",
    "  $(window).load(function(){\n",
    "    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "  });\n",
    "\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<style type=\"text/css\">\n",
    "  div#preloader { position: fixed;\n",
    "      left: 0;\n",
    "      top: 0;\n",
    "      z-index: 999;\n",
    "      width: 100%;\n",
    "      height: 100%;\n",
    "      overflow: visible;\n",
    "      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center;\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<div id=\"preloader\"></div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load rpy2 magic\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# to switch off warning messages\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# make default cell width 85% of available screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:85% !important; }</style>\"))\n",
    "\n",
    "# load R libraries & functions\n",
    "%R options(warn=-1)\n",
    "%R library(RColorBrewer)\n",
    "%R library(ComplexHeatmap)\n",
    "%R library(circlize)\n",
    "%R library(dendextend)\n",
    "%R library(Rtsne)\n",
    "%R library(ggplot2)\n",
    "%R library(gridExtra)\n",
    "%R source(\"/gfs/devel/tkhoyratty/my_scripts/R/pca.R\")\n",
    "%R library(wesanderson)\n",
    "%R Palette <- wes_palette(\"Cavalcanti1\")\n",
    "\n",
    "# load python modules\n",
    "import glob\n",
    "import re\n",
    "import sys\n",
    "import os\n",
    "import rpy2.robjects as robjects\n",
    "import CGAT.Database as DB\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "db = \"./csvdb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ATAC Pipeline Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get peak/readcounts to use from pipeline.yml\n",
    "import yaml\n",
    "\n",
    "with open(\"pipeline.yml\") as o:\n",
    "    opts = yaml.load(o)\n",
    "#     print(opts)\n",
    "    \n",
    "filt = opts[\"macs2\"][\"peaks\"]\n",
    "# print(filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import counts & upper quantile normalise\n",
    "def get_counts(filt=filt, db=db):\n",
    "    # get counts, filter on fragment size\n",
    "\n",
    "    if filt == \"size_filt\":\n",
    "        peaks = \"<150bp\"\n",
    "    if filt == \"all\":\n",
    "        peaks = \"all_fragments\"\n",
    "        \n",
    "    statement = '''select sample_id, peak_id, RPM_width_norm *1000 as RPM \n",
    "                from all_norm_counts where size_filt == \"%(peaks)s\" ''' % locals()\n",
    "        \n",
    "    df = DB.fetch_DataFrame(statement, db)\n",
    "\n",
    "    df = df.pivot(\"sample_id\", \"peak_id\", \"RPM\").transpose()\n",
    "    df.index.name = None\n",
    "\n",
    "    # normalise to upper quantiles forC between sample comparison\n",
    "    df = df.div(df.quantile(0.75, axis=0), axis=1) \n",
    "    \n",
    "    return df\n",
    "\n",
    "counts = get_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sample_info table\n",
    "sample_info = DB.fetch_DataFrame('''select distinct * from sample_info''', db)\n",
    "sample_info.index = sample_info[\"sample_id\"]\n",
    "sample_info.index.name = None\n",
    "sample_info.head(len(sample_info))\n",
    "\n",
    "sample_info.head(len(sample_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br>\n",
    "\n",
    "## Sample Quality \n",
    "- Contamination with mitochondrial reads is a common problem for ATAC datasets\n",
    "- As are PCR duplicates from library prep\n",
    "- high values indicate low quality libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_stats(paired=True, db=db, sample_info=sample_info):\n",
    "    '''Collect all mapping stats & retrun df for plotting'''\n",
    "    \n",
    "    if paired==True:\n",
    "        reads = DB.fetch_DataFrame('''select READS_ALIGNED_IN_PAIRS/2 as MAPPED_PAIRS, PCT_READS_ALIGNED_IN_PAIRS, \n",
    "                                      TOTAL_READS, PCT_ADAPTER, sample_id from picardAlignmentSummary \n",
    "                                      where CATEGORY = \"PAIR\" ''', db)\n",
    "    if paired==False:\n",
    "        print(\"Update function for non-paired data\")\n",
    "    \n",
    "    # Format mapping qc df\n",
    "    reads[\"Filter\"] = reads[\"sample_id\"].apply(lambda x: x.split(\".\")[-1])\n",
    "    reads[\"Filter\"] = reads[\"sample_id\"].apply(lambda x: x.split(\"_\")[-1] if \"size_filt_prep\" not in x else \"prep<150bp\")\n",
    "    reads[\"sample_id\"] = reads[\"sample_id\"].apply(lambda x: '_'.join(x.split(\"_\")[0:-1]))\n",
    "    reads[\"sample_id\"] = reads[\"sample_id\"].apply(lambda x: x.split(\".\")[0])\n",
    "\n",
    "    if len(sample_info)==0:\n",
    "        print(\"Provide sample_info df with sample annotations\")\n",
    "        \n",
    "    reads = pd.merge(reads, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "    \n",
    "    # get no. reads mapping to chrM\n",
    "    chrm = DB.fetch_DataFrame('''select * from allContig''', db)\n",
    "    \n",
    "    # reformat df\n",
    "    chrm = chrm.pivot(\"sample_id\", \"contig\", \"mapped_reads\")\n",
    "    chrm[\"total_mapped_reads\"] = chrm.sum(axis=1)\n",
    "    chrm[\"sample_id\"] = chrm.index.values\n",
    "    chrm.index.name = None\n",
    "    chrm = chrm[[\"chrM\", \"total_mapped_reads\", \"sample_id\"]]\n",
    "    chrm[\"pct_chrM\"] = chrm[\"chrM\"] / chrm[\"total_mapped_reads\"] *100 # % reads mapping to chrM\n",
    "\n",
    "    # annotate df\n",
    "    chrm[\"sample_id\"] = chrm[\"sample_id\"].apply(lambda x: str(x).split(\".\")[0])\n",
    "    chrm = pd.merge(chrm, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "    chrm[\"Filter\"] = \"genome\" # chrM only in genomic reads as filtered out after, others not tested\n",
    "\n",
    "    df = pd.merge(reads, chrm[[\"pct_chrM\", \"sample_id\", \"Filter\"]], how=\"outer\", on=[\"sample_id\", \"Filter\"])\n",
    "    \n",
    "    return df\n",
    "\n",
    "mapping_qc = mapping_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get no. reads mapping to chrM\n",
    "chrm = DB.fetch_DataFrame('''select * from allContig''', db)\n",
    "\n",
    "# reformat df\n",
    "chrm = chrm.pivot(\"sample_id\", \"contig\", \"mapped_reads\")\n",
    "chrm[\"total_mapped_reads\"] = chrm.sum(axis=1)\n",
    "chrm[\"sample_id\"] = chrm.index.values\n",
    "chrm.index.name = None\n",
    "chrm = chrm[[\"chrM\", \"total_mapped_reads\", \"sample_id\"]]\n",
    "chrm[\"pct_chrM\"] = chrm[\"chrM\"] / chrm[\"total_mapped_reads\"] *100 # % reads mapping to chrM\n",
    "\n",
    "# annotate df\n",
    "chrm[\"sample_id\"] = chrm[\"sample_id\"].apply(lambda x: str(x).split(\".\")[0])\n",
    "chrm = pd.merge(chrm, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "chrm[\"Filter\"] = \"genome\" # chrM only in genomic reads as filtered out after, others not tested\n",
    "\n",
    "# chrm.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i chrm -h 400 -w 450\n",
    "\n",
    "# Palette <- c(\"darkorange3\", \"slateblue2\", \"darkgray\", \"seagreen4\")\n",
    "\n",
    "ggplot(chrm, aes(y=pct_chrM, x=sample_id, fill=condition)) +\n",
    "    geom_bar(stat=\"identity\", colour=\"black\") +\n",
    "    scale_fill_manual(values=Palette) +\n",
    "    coord_flip() +\n",
    "    theme_Publication() +\n",
    "    labs(x=\"\", title=\"chrM Contamination\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dups = mapping_qc.pivot(\"sample_id\", \"Filter\", \"MAPPED_PAIRS\")\n",
    "dups[\"duplicates\"] = dups[\"filt\"] - dups[\"prep\"]\n",
    "dups = pd.DataFrame(dups.to_records())\n",
    "dups = pd.merge(dups, sample_info, how=\"inner\", on=\"sample_id\")\n",
    "# dups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i dups -h 400 -w 550\n",
    "\n",
    "ggplot(dups, aes(y=duplicates, x=sample_id, fill=condition)) +\n",
    "    geom_bar(stat=\"identity\", colour=\"black\") +\n",
    "    scale_fill_manual(values=Palette) +\n",
    "    coord_flip() +\n",
    "    theme_Publication() +\n",
    "    labs(x=\"\", title=\"PCR Duplicates\", y=\"No. Read Pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br>\n",
    "\n",
    "## Insert sizes\n",
    "- nucleosomal phasing should be apparent in library insert size distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fragment_stats(db=db, sample_info=sample_info):\n",
    "    '''Collect insert size stats & format df for plotting'''\n",
    "    \n",
    "    def clean(df):\n",
    "        df[\"Filter\"] = df[\"sample_id\"].apply(lambda x: x.split(\".\")[-1])\n",
    "        df[\"Filter\"] = df[\"sample_id\"].apply(lambda x: x.split(\"_\")[-1] if \"size_filt_prep\" not in x else \"prep<150bp\")\n",
    "        df[\"sample_id\"] = df[\"sample_id\"].apply(lambda x: x.rstrip(\"_prep\"))\n",
    "        df[\"sample_id\"] = df[\"sample_id\"].apply(lambda x: x.split(\".\")[0])\n",
    "        df = pd.merge(df, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "        return df\n",
    "    \n",
    "    insert_sizes = DB.fetch_DataFrame('''select * from picardInsertSizeHistogram where sample_id like \"%prep\"''', db)\n",
    "    size_stats = DB.fetch_DataFrame('''select * from picardInsertSizeMetrics where sample_id like \"%prep\"''', db)\n",
    "\n",
    "    insert_sizes = clean(insert_sizes)\n",
    "    size_stats = clean(size_stats)\n",
    "\n",
    "    return [size_stats, insert_sizes]\n",
    "\n",
    "(size_stats, insert_sizes) = fragment_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir QC_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df[\"Filter\"] = df[\"sample_id\"].apply(lambda x: x.split(\".\")[-1])\n",
    "    df[\"Filter\"] = df[\"sample_id\"].apply(lambda x: x.split(\"_\")[-1] if \"size_filt_prep\" not in x else \"prep<150bp\")\n",
    "    df[\"Filter\"] = df[\"Filter\"].apply(lambda x: x.replace(\"prep<150bp\", \"<150bp\"))\n",
    "    df[\"Filter\"] = df[\"Filter\"].apply(lambda x: x.replace(\"prep\", \"all\"))\n",
    "    df[\"sample_id\"] = df[\"sample_id\"].apply(lambda x: x.rstrip(\"_prep\"))\n",
    "    df[\"sample_id\"] = df[\"sample_id\"].apply(lambda x: x.split(\".\")[0])\n",
    "    df = pd.merge(df, sample_info, on=\"sample_id\", how=\"inner\")\n",
    "    return df\n",
    "    \n",
    "def insertSizePlots(outfiles):\n",
    "    '''Collect insert size metrics & generate plots'''\n",
    "    \n",
    "    sample_info = DB.fetch_DataFrame('''select * from sample_info''', db)\n",
    "\n",
    "    insert_sizes = DB.fetch_DataFrame('''select * from picardInsertSizeHistogram where sample_id like \"%prep\"''', db)\n",
    "    insert_sizes = clean(insert_sizes)\n",
    "#     print(insert_sizes.head())\n",
    "    insert_sizes.to_csv(outfiles[3], sep=\"\\t\", header=True, index=False)\n",
    "\n",
    "    # plots\n",
    "    sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "    # all\n",
    "    plt.figure(figsize=(10,6))\n",
    "    sns_fragment_hist_all = sns.lineplot(data=insert_sizes[insert_sizes[\"Filter\"]==\"all\"], ci=None,\n",
    "                                           x=\"insert_size\", y=\"All_Reads.fr_count\", hue=\"condition\")\n",
    "    plt.title(\"All insert sizes\")\n",
    "    plt.savefig(outfiles[1])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # log2 scales\n",
    "    plt.figure(figsize=(10,6))\n",
    "    insert_sizes[\"log2_All_Reads_fr_count\"] = np.log2(insert_sizes[\"All_Reads.fr_count\"])\n",
    "    sns_fragment_hist_size_filt = sns.lineplot(data=insert_sizes[insert_sizes[\"Filter\"]==\"all\"], ci=None,\n",
    "                                           x=\"insert_size\", y=\"log2_All_Reads_fr_count\", hue=\"condition\")\n",
    "    plt.title(\"log2(All insert sizes\")\n",
    "    plt.savefig(outfiles[2])\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # box\n",
    "    sns_fragment_box = sns.catplot(data=insert_sizes, x=\"sample_id\", y=\"insert_size\", hue=\"Filter\", \n",
    "                                      kind=\"box\", height=5, aspect=2)#.set_title(\"Insert sizes per sample\")\n",
    "    plt.title(\"Insert sizes per sample\")\n",
    "    sns_fragment_box.savefig(outfiles[0])\n",
    "    sns_fragment_box.set_xticklabels(rotation=30, ha=\"right\")\n",
    "    \n",
    "insertSizePlots([\"QC_plots/fragment_box.png\",\n",
    "              \"QC_plots/fragment_hist_all.png\",\n",
    "              \"QC_plots/fragment_hist_all_log2.png\",\n",
    "              \"QC_plots/insert_sizes.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_info = DB.fetch_DataFrame('''select * from sample_info''', db)\n",
    "\n",
    "insert_sizes = DB.fetch_DataFrame('''select * from picardInsertSizeHistogram where sample_id like \"%prep\"''', db)\n",
    "insert_sizes = clean(insert_sizes)\n",
    "insert_sizes = insert_sizes.sort_values(\"sample_id\")\n",
    "\n",
    "# plots\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "for s in set(insert_sizes[\"condition\"]):\n",
    "\n",
    "    # all\n",
    "    plt.figure(figsize=(10,6))\n",
    "    \n",
    "    df = insert_sizes[insert_sizes[\"condition\"]==s]\n",
    "    sns_fragment_hist_all = sns.lineplot(data=df[df[\"Filter\"]==\"all\"], ci=None,\n",
    "                                           x=\"insert_size\", y=\"All_Reads.fr_count\", hue=\"sample_id\")\n",
    "    plt.title(s)\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br>\n",
    "\n",
    "## Mapping QC\n",
    "* All mapped reads are contained in \"genome\"\n",
    "* \"filt\" contains reads with MAPQ scores >10 & has reads mapping to chrM subtracted\n",
    "* Reads in \"prep\" have PCR duplicates subtracted\n",
    "* \"prep<150bp\" files are further filtered for reads with insert sizes < 150 b.p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R\n",
    "\n",
    "# R functions\n",
    "\n",
    "get_legend <- function(a.gplot){ \n",
    "  tmp <- ggplot_gtable(ggplot_build(a.gplot)) \n",
    "  leg <- which(sapply(tmp$grobs, function(x) x$name) == \"guide-box\") \n",
    "  legend <- tmp$grobs[[leg]] \n",
    "  return(legend)\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i mapping_qc -w 800 -h 750\n",
    "\n",
    "test <- ggplot(mapping_qc, aes(y=MAPPED_PAIRS, x=sample_id, colour=condition, shape=Filter)) + \n",
    "        geom_point(size=6) + \n",
    "        theme_Publication()\n",
    "        \n",
    "a <- ggplot(mapping_qc, aes(y=MAPPED_PAIRS, x=sample_id, colour=condition, shape=Filter)) + \n",
    "        geom_point(size=6) + \n",
    "        theme_Publication() +           \n",
    "        theme(axis.text.x=element_text(angle=45, hjust=1)) + \n",
    "        scale_y_continuous(limits=c(0, 65000000)) +\n",
    "        scale_colour_manual(values=Palette) +\n",
    "        labs(x=\"\", y=\"Mapped Pairs\") +\n",
    "        geom_hline(yintercept=25000000, lty=\"dashed\", col=\"black\")\n",
    "\n",
    "b <- ggplot(subset(mapping_qc, Filter==\"genome\"), \n",
    "            aes(y=PCT_READS_ALIGNED_IN_PAIRS*100, x=sample_id, colour=condition)) + \n",
    "        geom_point(size=6, shape=17) + \n",
    "        theme_Publication() +           \n",
    "        theme(axis.text.x=element_text(angle=45, hjust=1)) + \n",
    "        labs(y=\"% Reads in Pairs\", x=\"\") +\n",
    "        scale_y_continuous(limits=c(0, 100)) +\n",
    "        scale_colour_manual(values=Palette)\n",
    "\n",
    "c <- ggplot(mapping_qc, aes(y=PCT_ADAPTER, x=sample_id, colour=condition, shape=Filter)) + \n",
    "        geom_point(size=6) + \n",
    "        theme_Publication() +           \n",
    "        theme(axis.text.x=element_text(angle=45, hjust=1)) + \n",
    "        scale_colour_manual(values=Palette) +\n",
    "        labs(x=\"\", y=\"% Adaptor\")\n",
    "\n",
    "d <- ggplot(mapping_qc, aes(y=pct_chrM, x=sample_id, colour=condition)) + \n",
    "        geom_point(size=6, shape=17) +\n",
    "        theme_Publication() +\n",
    "        labs(x=\"\", y= \"% chrM Reads\") +\n",
    "        scale_y_continuous(limits=c(0,100)) +          \n",
    "        theme(axis.text.x=element_text(angle=45, hjust=1)) + \n",
    "        scale_colour_manual(values=Palette)\n",
    "\n",
    "legend <- get_legend(a)\n",
    "\n",
    "grid.arrange(a + theme(legend.position=\"none\"), b + theme(legend.position=\"none\"), \n",
    "             c + theme(legend.position=\"none\"), d + theme(legend.position=\"none\"), \n",
    "             ncol=2, nrow=2, bottom=legend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br>\n",
    "\n",
    "## TSS Enrichment\n",
    "### Normalised ATAC signal over all TSSs\n",
    "\n",
    "All_fragments | Size_filt\n",
    "- | -\n",
    "![alternate text](deeptools.dir/TSS.all.heatmap.png) | ![alternate text](deeptools.dir/TSS.size_filt.heatmap.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Called peaks relative to nearest TSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tss_dist(db=db):\n",
    "\n",
    "    statement = '''select distinct a.sample_id, a.peak_id, a.size_filt, c.strand || \"\" || b.TSSdist as TSSdist\n",
    "                from all_norm_counts a, merged_peaks_GREAT_annotated b,\n",
    "                ensemblGeneset c where a.peak_id = b.peak_id \n",
    "                and b.gene_id = c.gene_id '''\n",
    "    \n",
    "    df = DB.fetch_DataFrame(statement, db)\n",
    "    \n",
    "    df[\"TSSdist\"] = df[\"TSSdist\"].apply(lambda x: float(x.replace(\"+\", \"\")))\n",
    "#     df[\"TSSdist\"] = df[\"TSSdist\"].astype(int)\n",
    "    \n",
    "    return df\n",
    "    \n",
    "df = get_tss_dist()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i df -w 600 -h 400\n",
    "\n",
    "p2 <- ggplot(df, aes(TSSdist/1000, fill=size_filt)) + \n",
    "            geom_histogram(position=\"dodge\", aes((y=c(..count..[..group..==1]/sum(..count..),\n",
    "                                 ..count..[..group..==2]/sum(..count..))*100), x=TSSdist/1000)) + \n",
    "            labs(y=\"Percent Total Peaks\", x=\"TSS distance (kb)\", title=\"\") + \n",
    "        theme_Publication() +\n",
    "        scale_fill_manual(values=Palette)\n",
    "\n",
    "p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br>\n",
    "\n",
    "## Peakcalling QC\n",
    "### All peaks\n",
    "* All detected peaks with & without filtering reads by size & fraction of reads in peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_stats = DB.fetch_DataFrame('''select a.no_peaks, a.size_filt, b.FRIP, b.sample_id from no_peaks a, \n",
    "                                frip_table b where a.sample_id=b.sample_id and a.size_filt=b.size_filt ''', db)\n",
    "\n",
    "peak_stats = pd.merge(peak_stats, sample_info, how=\"inner\", on=\"sample_id\")\n",
    "peak_stats.head(len(peak_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i peak_stats  -w 800 -h 350\n",
    "\n",
    "no_peaks <- ggplot(peak_stats, \n",
    "                   aes(y=no_peaks, x=sample_id, fill=condition, \n",
    "                       shape=factor(replicate), alpha=size_filt)) + \n",
    "                geom_text(aes(label=paste0(\"r\", replicate)), \n",
    "                          position=position_dodge(width=1), vjust=-0.5, fontface=\"bold\", size=4.5, show.legend=F) +\n",
    "                geom_bar(stat=\"identity\", position=\"dodge\", colour=\"black\") + theme_Publication() +\n",
    "                theme(axis.text.x=element_text(angle=45, hjust=1)) + \n",
    "                scale_alpha_discrete(range=c(0.4, 1)) +\n",
    "                labs(y=\"No. Peaks\", y=\"\", x=\"\") +\n",
    "                scale_y_continuous(limits=c(0, max(peak_stats$no_peaks))) +\n",
    "                scale_fill_manual(values=Palette) \n",
    "                \n",
    "frip_plot <- ggplot(peak_stats, \n",
    "                    aes(y=FRIP, x=sample_id, fill=condition,\n",
    "                        alpha=size_filt)) + \n",
    "                geom_text(aes(label=paste0(\"r\", replicate)), \n",
    "                          position=position_dodge(width=1), vjust=-0.5, fontface=\"bold\", size=4.5, show.legend=F) +\n",
    "                geom_bar(stat=\"identity\", position=\"dodge\", colour=\"black\") + theme_Publication() +          \n",
    "                theme(axis.text.x=element_text(angle=45, hjust=1)) + \n",
    "                scale_alpha_discrete(range=c(0.4, 1)) +\n",
    "                labs(y=\"FRIP\", x=\"\") +\n",
    "                scale_y_continuous(limits=c(0,1)) + \n",
    "                scale_fill_manual(values=Palette) +\n",
    "                guides(colour=guide_legend(override.aes=list(size=6)), \n",
    "                       alpha=guide_legend(override.aes=list(size=6))) +\n",
    "                geom_hline(yintercept=0.2, lty=\"dashed\", colour=\"black\") \n",
    "\n",
    "key <- get_legend(frip_plot)\n",
    "\n",
    "grid.arrange(no_peaks + theme(legend.position=\"none\"), frip_plot + theme(legend.position=\"none\"),\n",
    "             ncol=2, nrow=1, bottom=key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High confidence peaks\n",
    "* Peaks which are consistent between biological replicates, from size filtered & non- size filtered peak sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_peaks = DB.fetch_DataFrame('''select * from no_peaks where merged like \"%merged\" ''', db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i merged_peaks -w 600 -h 400\n",
    "\n",
    "ggplot(merged_peaks, aes(y=no_peaks, x=sample_id, alpha=size_filt, fill=sample_id)) +\n",
    "    geom_bar(stat=\"identity\", position=\"dodge\", colour=\"black\") +\n",
    "    scale_alpha_discrete(range=c(0.4, 1)) +\n",
    "    scale_fill_manual(values=Palette, guide=FALSE) +\n",
    "    theme_Publication() +\n",
    "    labs(x=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<br>\n",
    "\n",
    "\n",
    "## Data Exploration \n",
    "* based on counts over merged peakset\n",
    "* merged peakset consists of all detected peaks \n",
    "* counts are normalised for sequencing depth, peak width, and upper quantile normalised for between sample comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson correlation between nomalised counts in consensus peakset\n",
    "* clustering with Ward method on Manhattan distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%R colnames(counts) <- sample_info$sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -i counts\n",
    "\n",
    "cm <- data.matrix(log2(counts +1))\n",
    "m <- cor(cm, method=\"pearson\", use=\"all\")\n",
    "\n",
    "distr <- dist(m, method=\"manhattan\")\n",
    "clustr <- hclust(distr, method=\"ward.D2\")\n",
    "dendr <- as.dendrogram(clustr)\n",
    "dendr <- dendr %>% sort(type=\"labels\")\n",
    "\n",
    "distc <- dist(t(m), method=\"manhattan\")\n",
    "clustc <- hclust(distc, method=\"ward.D2\")\n",
    "dendc <- as.dendrogram(clustc)\n",
    "dendc <- rev(dendc) %>% sort(type=\"labels\")\n",
    "\n",
    "p2 <- Heatmap(m,\n",
    "       col = colorRamp2(c(min(m), max(m)), c(\"white\", \"#02401B\")),\n",
    "       cluster_rows=dendr,\n",
    "       cluster_columns=dendc,\n",
    "       column_dend_reorder = FALSE,\n",
    "       column_dend_height = unit(2, \"cm\"),\n",
    "       row_dend_width = unit(2, \"cm\"),\n",
    "       row_names_gp=gpar(fontsize=16),\n",
    "       column_names_gp=gpar(fontsize=16),\n",
    "       name=\"Pearson Correlation:\",\n",
    "       heatmap_legend_param=list(legend_direction=\"horizontal\", \n",
    "#                                   at=c(0.9, 1), \n",
    "                                  color_bar = \"continuous\",\n",
    "                                  legend_width = unit(5, \"cm\"), \n",
    "                                  title_position = \"lefttop\",\n",
    "                                  title_gp=gpar(fontsize=18),\n",
    "                                  labels_gp=gpar(fontsize=14)),\n",
    "       )\n",
    "\n",
    "draw(p2, heatmap_legend_side = \"bottom\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R  -w 1200 -h 300 -i sample_info\n",
    "\n",
    "ggplot_prcomp <- function(prcomp_object,\n",
    "                          plots=list(\"A\"=c(\"PC1\",\"PC2\"), \"B\"=c(\"PC3\",\"PC4\"), \"C\"=c(\"PC5\",\"PC6\")),\n",
    "                          sample_information=\"none\",\n",
    "                          fill=\"c()\",\n",
    "                          shape=\"c()\",\n",
    "                          label=\"none\",\n",
    "                          color=\"c()\",\n",
    "                          alpha=\"c()\",\n",
    "                          size=3,\n",
    "                          nudge_scale_factor=40){\n",
    "    require(gridExtra)\n",
    "    pca = prcomp_object\n",
    "\n",
    "    # sample_information should have the same rownames as pca$x\n",
    "    pvs <- summary(pca)$importance[\"Proportion of Variance\",]\n",
    "\n",
    "    names = paste(names(pvs),\" (\",round(pvs,2),\")\",sep=\"\")\n",
    "\n",
    "    #scree plot\n",
    "    fs <- data.frame(x=c(1:length(names(pvs))), y=as.vector(pvs))\n",
    "\n",
    "    pcdf <- as.data.frame(pca$x)\n",
    "    \n",
    "    pcdf <- merge(pcdf, sample_information, by=0, all=T)\n",
    "\n",
    "    gps = list()\n",
    "\n",
    "    scree <- ggplot(fs, aes(x,y)) + \n",
    "                geom_point(size=4) + \n",
    "                xlab(\"principal component\") + \n",
    "                ylab(\"proportion of variance\") + \n",
    "                ggtitle(\"scree plot\") +\n",
    "                theme_Publication()\n",
    "\n",
    "    c_lab <- function(props, C){\n",
    "        return(paste(C, \" (\", props[[C]]*100,\"%)\",sep=\"\"))\n",
    "    }\n",
    "\n",
    "    for(plot in names(plots)){\n",
    "\n",
    "        comps <- plots[[plot]]\n",
    "\n",
    "        PCX <- comps[1]\n",
    "        PCY <- comps[2]\n",
    "\n",
    "        nudge_x <- diff(range(pcdf[[PCX]]))/nudge_scale_factor\n",
    "        nudge_y <- diff(range(pcdf[[PCY]]))/nudge_scale_factor\n",
    "\n",
    "        gp <- ggplot(pcdf, aes_string(PCX, PCY, fill=fill, colour=color)) +\n",
    "#                 scale_shape_manual(values=c(21,22,23,24,25)) +\n",
    "                scale_alpha_discrete(range=c(0.5, 1)) +\n",
    "                theme_Publication()\n",
    "\n",
    "        gp <- gp + geom_point(size=size, height=15, width=15, shape=21)\n",
    "        \n",
    "        if(label!=\"none\"){\n",
    "            gp <- gp + geom_text_repel(aes_string(label=label),  color=\"black\", check_overlap=T, force=5)\n",
    "        }\n",
    "        \n",
    "        gp <- gp + xlab(c_lab(pvs,PCX)) + ylab(c_lab(pvs,PCY))\n",
    "\n",
    "        gps[[plot]] <- gp\n",
    "\n",
    "    }\n",
    "\n",
    "    gps[[\"scree\"]] <- scree\n",
    "\n",
    "    return(gps)\n",
    "}\n",
    "\n",
    "df <- as.data.frame(log2(counts+1))\n",
    "\n",
    "pca <- prcomp(t(df), scale=FALSE)\n",
    "rownames(sample_info) <- sample_info$category\n",
    "\n",
    "pca_plots <- ggplot_prcomp(pca, \n",
    "             plots=list(\"A\"=c(\"PC1\",\"PC2\"), \"B\"=c(\"PC3\", \"PC4\"), \"C\"=c(\"PC5\", \"PC6\")),\n",
    "             sample_information=sample_info, \n",
    "             fill=\"condition\",\n",
    "             size=8,\n",
    "             nudge_scale_factor=30) \n",
    "\n",
    "a <- pca_plots$A + scale_fill_manual(values=Palette)\n",
    "b <- pca_plots$B + scale_fill_manual(values=Palette)\n",
    "c <- pca_plots$C + scale_fill_manual(values=Palette)\n",
    "s <- pca_plots$scree\n",
    "\n",
    "a <- a + theme(legend.direction=\"horizontal\", legend.box=\"horizontal\")\n",
    "legend <- get_legend(a)\n",
    "blank <- grid.rect(gp=gpar(col=\"white\"))                      \n",
    "\n",
    "grid.arrange(a + theme(legend.position=\"none\"), b + theme(legend.position=\"none\"), c + theme(legend.position=\"none\"), s, \n",
    "             bottom=legend, ncol=4, nrow=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R -h 400 -w 500\n",
    "                           \n",
    "tsne_out <- Rtsne(t(df), pca=T, perplexity=4)\n",
    "tsne_df <- as.data.frame(tsne_out$Y)\n",
    "rownames(tsne_df) <- colnames(log2counts)\n",
    "colnames(tsne_df) <- c(\"tSNE1\", \"tSNE2\")\n",
    "tsne_df$category <- rownames(tsne_df)\n",
    "\n",
    "tsne_df <- merge(tsne_df, sample_info, by.x=\"category\", by.y=\"sample_id\")\n",
    "\n",
    "p <- ggplot(tsne_df, aes(y=tSNE1, x=tSNE2, shape=category.y, fill=condition, colour=stimuli)) + \n",
    "        geom_point(size=7, stroke=2) + \n",
    "        theme_Publication()  + \n",
    "        scale_colour_manual(values=c(\"black\", \"red3\")) +\n",
    "        scale_fill_manual(values=Palette) + \n",
    "        scale_shape_manual(values=c(21,22)) +\n",
    "        labs(title=\"tSNE of Normalised Read Counts \\nOver All Peaks\") +\n",
    "        theme(legend.position=\"right\", legend.direction=\"vertical\") +\n",
    "        guides(fill=guide_legend(override.aes=list(shape=21)))\n",
    "\n",
    "grid.arrange(p, ncol=1, nrow=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replicate correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# use sample information to get no. replicates & conditions\n",
    "rep_pairs = sample_info.pivot(\"sample_group\", \"replicate\", \"sample_id\").transpose()\n",
    "rep_pairs.columns.name = None\n",
    "rep_pairs.index.name = None\n",
    "\n",
    "# report replicates to dict\n",
    "reps = {}\n",
    "for col in rep_pairs.columns:\n",
    "    reps[col]=[rep_pairs[col].iloc[0], rep_pairs[col].iloc[1]]\n",
    "\n",
    "# get palette\n",
    "colours = [\"light red\", \"windows blue\", \"dusty purple\", \"greyish\", \"amber\", \"faded green\"]\n",
    "pal = sns.xkcd_palette(colours)\n",
    "\n",
    "if len(rep_pairs.transpose()) > len(pal):\n",
    "    import random\n",
    "    \n",
    "    extra_colours = sns.xkcd_rgb.keys() # all 954 colours\n",
    "    pal2 = sns.xkcd_palette(extra_colours)\n",
    "    pal = pal + random.sample(pal2, len(pal2))\n",
    "    \n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")# set seaborn theme\n",
    "\n",
    "from scipy import stats\n",
    "def pearsonr(x, y):\n",
    "    return stats.pearsonr(x, y)[0]\n",
    "\n",
    "# use dict to subset df of normalised counts & plot rep correlations\n",
    "n = 0\n",
    "for key in reps:\n",
    "    n = n + 1\n",
    "    c = n - 1\n",
    "    df = counts[reps[key]]\n",
    "    df.columns = [\"Rep1\", \"Rep2\"]\n",
    "    p = sns.jointplot(data=np.log2(df+1), y=\"Rep1\", x=\"Rep2\", kind=\"reg\", size=7, color=pal[c], stat_func=pearsonr)\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    p.fig.suptitle(key) # add title\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
