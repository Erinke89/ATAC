"""===========================
Pipeline template
===========================

.. Replace the documentation below with your own description of the
   pipeline's purpose

Overview
========

This pipeline uses FIMO to search for motif occurences in a set of
intervals (e.g. ChIP or ATAC -seq peaks).

Usage
=====

See :ref:`PipelineSettingUp` and :ref:`PipelineRunning` on general
information how to use CGAT pipelines.

Configuration
-------------

The pipeline requires a configured :file:`pipeline.ini` file.
CGATReport report requires a :file:`conf.py` and optionally a
:file:`cgatreport.ini` file (see :ref:`PipelineReporting`).

Default configuration files can be generated by executing:

   python <srcdir>/pipeline_motifenrichment.py config

Input files
-----------
*** all input files shoule be in data.dir/ ***

1) BED files of intervals
2) database of MEME formatted motifs 
   - motifs of interest specified in pipeline.ini
3) *optional* custom MEME motifs
   - named "motif".meme


Requirements
------------

The pipeline requires the results from
:doc:`pipeline_annotations`. Set the configuration variable
:py:data:`annotations_database` and :py:data:`annotations_dir`.

On top of the default CGAT setup, the pipeline requires the following
software to be in the path:

.. Add any additional external requirements such as 3rd party software
   or R modules below:

Requirements:

* samtools >= 1.1

Pipeline output
===============
- BED files of motif occurences
- histograms of motif enrichment over intervals


Glossary
========

.. glossary::


Code
====

"""
from ruffus import *

import sys
import os
import sqlite3
import CGAT.Experiment as E
import CGATPipelines.Pipeline as P
import glob
import CGAT.Database as DB
import pandas as pd

# load options from the config file
PARAMS = P.getParameters(
    ["%s/pipeline.ini" % os.path.splitext(__file__)[0],
     "../pipeline.ini",
     "pipeline.ini"])

# add configuration values from associated pipelines
#
# 1. pipeline_annotations: any parameters will be added with the
#    prefix "annotations_". The interface will be updated with
#    "annotations_dir" to point to the absolute path names.
PARAMS.update(P.peekParameters(
    PARAMS["annotations_dir"],
    "pipeline_genesets.py",
    on_error_raise=__name__ == "__main__",
    prefix="annotations_",
    update_interface=True))


# if necessary, update the PARAMS dictionary in any modules file.
# e.g.:
#
# import CGATPipelines.PipelineGeneset as PipelineGeneset
# PipelineGeneset.PARAMS = PARAMS
#
# Note that this is a hack and deprecated, better pass all
# parameters that are needed by a function explicitely.

# -----------------------------------------------
# Utility functions
def connect():
    '''utility function to connect to database.

    Use this method to connect to the pipeline database.
    Additional databases can be attached here as well.

    Returns an sqlite3 database handle.
    '''

    dbh = sqlite3.connect(PARAMS["database_name"])
    statement = '''ATTACH DATABASE '%s' as annotations''' % (
        PARAMS["annotations_database"])
    cc = dbh.cursor()
    cc.execute(statement)
    cc.close()

    return dbh


# ---------------------------------------------------
# Specific pipeline tasks
@follows(mkdir("meme.seq.dir"))
@transform("data.dir/*.bed",
          regex(r"data.dir/(.*).bed"),
          r"meme.seq.dir/\1.foreground.bed")
def offsetPeaks(infile, outfile):
    '''Offset peaks to peak centre +/- n b.p. (default 500)

       * If peak summit is specified in column 6 of BED,  *
       * specify in pipeline.ini "fimo_summit", otherwise *
       * peak centre will be used to specify intervals.   * 

    '''
    
    summits = PARAMS["fimo_summits"]
    offset = int(PARAMS["fimo_window"]/2)-1 
    chrom_sizes = PARAMS["annotations_chrom_sizes"]
    tmp_dir = "$SCRATCH_DIR"

    statement_start ='''tmp=`mktemp -p %(tmp_dir)s`; checkpoint; 
                        awk 'BEGIN {OFS="\\t"}'''
    
    if summits == "True":
        opts = '''{start=$6-1} {end=$6+1}'''
    else:
        opts = '''{x=($3-$2)/2} {centre=$2+x} {start=centre-1} {end=centre+1} '''

    statement_end = '''{print $1,int(start),int(end),$4}'
                         %(infile)s
                         > $tmp ; checkpoint;
                       slopBed
                         -g %(chrom_sizes)s
                         -b %(offset)s
                         -i $tmp
                         > %(outfile)s'''
    
    statement = ''.join([statement_start, opts, statement_end])

    P.run()


@transform(offsetPeaks,
           suffix(r".bed"),
           r".load")
def loadPeaks(infile, outfile):
    '''load peak intervals'''

    # change this task to submit statement to cluster
    P.load(infile, outfile, options='-H "chr,start,end,peak_id" ')
    

@follows(loadPeaks)
@transform(offsetPeaks,
           regex(r"(.*).foreground.bed"),
           r"\1.background.bed")
def getMemeBackgroundBed(infile, outfile):
    '''get bed file of peak flanking regions 
       (of equal width to peak) 
       for meme background model'''

    genome_idx = os.path.join(PARAMS["annotations_dir"],"assembly.dir/contigs.tsv")

    statement ='''sort 
                    -k1,1 
                    -k2,2n 
                    %(infile)s | 
                  bedtools flank 
                    -pct 
                    -l 1 
                    -r 1 
                    -g %(genome_idx)s 
                    > %(outfile)s'''

    P.run()

    
@follows(getMemeBackgroundBed)
@transform("meme.seq.dir/*.bed",
           regex(r"(.*).bed"),
           r"\1.fasta")
def getMemeSequences(infile, outfile):
    '''Get the peak sequences. 
       The genome sequences are already repeat soft-masked'''
  
    genome_fasta = os.path.join(PARAMS["genome_dir"],PARAMS["genome"]+".fasta")
    genome_idx = os.path.join(PARAMS["annotations_dir"],"assembly.dir/contigs.tsv")

    statement = '''fastaFromBed 
                     -name
                     -fi %(genome_fasta)s 
                     -bed %(infile)s 
                     -fo %(outfile)s'''

    P.run()


@follows(getMemeSequences)
@transform("meme.seq.dir/*background.fasta",
           suffix(".fasta"),
           ".bfile")
def getMemeBfiles(infile, outfile):
    '''prepare the meme background model'''

    statement='''fasta-get-markov 
                   -m 0 
                   %(infile)s  
                   > %(outfile)s'''
    
    P.run()

    
@follows(getMemeBfiles)
def prepSequences():
    pass


@follows(mkdir("query_motifs.dir"))
@files(None, "query_motifs.dir/db_motifs.txt")
def filterTFDatabases(infile, outfile):
    '''Filter TF databases for selected motifs 
       specified in pipeline.ini'''

    TFdb = PARAMS["fimo_motif_db"]
    TFdb = TFdb.replace(",", " ")
    motifs = PARAMS["fimo_motifs"].split(",")

    for TF in motifs:

        TF = TF.replace(".", "") # remove problematic symbols
        TF = TF.replace("(", "")
        TF = TF.replace(")", "")
        
        statement = '''awk '/^MOTIF/ {p=0} /%(TF)s/ {p=1} p' 
                         <( cat %(TFdb)s ) 
                         >> %(outfile)s''' 

        P.run()


@transform(filterTFDatabases,
           suffix(".txt"),
           r".meme")
def addMemeMotifHeader(infile, outfile):
    '''prepend header to query motif .meme file'''

    TFdb = PARAMS["fimo_motif_db"].split(",")[0]
    tmp_dir = "$SCRATCH_DIR"
         
    statement = '''tmp=`mktemp -p %(tmp_dir)s`; checkpoint;
                   head -n9 %(TFdb)s | 
                   cat - %(infile)s 
                     > $tmp ; checkpoint ;
                   mv $tmp %(outfile)s'''

    P.run()


@transform(filterTFDatabases,
         regex(r"(.*).txt"),
         r"\1_motifIDs.load")
def getMotifIDs(infile, outfile):
    '''Create motif_ID:TF lookup table'''

    tmp_dir = "$SCRATCH_DIR"

    tablename = os.path.basename(infile).replace(".txt", "").replace(".", "_")
    filename = outfile.replace(".load", ".txt")
    options='-H "pattern_name,TF" '
   
    statement1 = '''tmp=`mktemp -p %(tmp_dir)s`; checkpoint;
                   grep "^MOTIF" %(infile)s | 
                   sed 's/MOTIF //' |
                   sed 's/(//' |
                   sed 's/)//' |
                   sed 's/\.//' |
                   sed 's/\///' |
                   sed 's/\\///' |
                   sed 's/://' |
                   sed 's/_//' |
                   tr -s "[[:blank:]]" "\\t" 
                   > $tmp; checkpoint; 
                   cat $tmp | '''

    # use sed to remove problematic chars e.g. ".", "(" etc. from motif names
    
    statement2 = P.build_load_statement(tablename, options=options, retry=True)
    
    statement3 = ''' > %(outfile)s; checkpoint;
                     mv $tmp %(filename)s'''

    statement = ''.join([statement1, statement2, statement3])
    
    to_cluster = True

    P.run()

        
@follows(getMotifIDs)
@active_if(bool(glob.glob("data.dir/*.meme")))
@transform("data.dir/*.meme",
           regex(r"data.dir/(.*).meme"),
           r"query_motifs.dir/\1.meme")
def symlinkCustomMotifs(infile, outfile):
    '''Symlink user supplied custom motifs to query_motifs.dir/'''

    statement = '''ln -sfn ../%(infile)s %(outfile)s'''

    P.run()


@follows(symlinkCustomMotifs, addMemeMotifHeader, mkdir("query_motifs.dir/motif_logos"))
@split("query_motifs.dir/*meme",
       "query_motifs.dir/motif_logos/*png")
def motifLogos(infiles, outfiles):
    '''Generate motif logos for all MEME motifs'''

    for infile in infiles: # run on each motif file seperately
        
        head, tail = os.path.split(infile)
        outdir = head + "/motif_logos/"

        # iterate over each motif in list of databases
        if "db_motifs" in infile:
            statement = '''for i in `grep "^MOTIF" %(infile)s | 
                                   tr -s "[[:blank:]]" "_" | 
                                       sed 's/MOTIF_//' `; 
                           do m=`echo $i | sed 's/_/\\t/' | cut -f1` ; 
                              o=`echo \\'$i".png"\\' | sed 's/\\///'`; 
                              ceqlogo -i %(infile)s
                                      -m $m 
                                      -t $i 
                                      -f PNG
                                      -o $o ; 
                           done ; checkpoint; 
                           mv *png %(outdir)s'''

        # or plot first motif in file for cutom motifs (should only be 1 motif/file)
        else:
            name = os.path.basename(infile)
            title = name.replace(".meme", "")
            outfile = outdir + name.replace(".meme", ".png")

            statement = '''ceqlogo 
                             -i1 %(infile)s 
                             -t %(title)s
                             -f PNG
                             -o %(outfile)s'''

        print(statement)

        P.run()
    

@follows(addMemeMotifHeader, getMotifIDs, symlinkCustomMotifs, motifLogos)
def prepMotifs():
    pass


def generateFimo():
    '''Generator for FIMO jobs.
    
       * MEME motifs can be added to query_motifs.dir/ and  *
       * with format "*.meme" will be included in FIMO jobs *

       * Background for FIMO can be local (0-order Markov from     *
       * flanking regions of peaks), or based on nucleotide        *
       * frequencies listed in motif file. Specify in pipeline.ini *

    '''
    
    background = PARAMS["fimo_background"]
    sequences = glob.glob("meme.seq.dir/*foreground.fasta")
    motifs = glob.glob("query_motifs.dir/*meme")
    outdir = "fimo.dir/"

    if len(sequences) == 0 or len(motifs) == 0:
        pass
    
    for seq in sequences:
        for motif in motifs:

            mname = os.path.basename(motif).replace(".meme", "")
            seqname = os.path.basename(seq).replace(".foreground.fasta", "")

            outfile = ''.join([outdir, seqname, ".", mname, ".fimo.log"])

            if background == "local":
                bgfile = seq.replace("foreground.fasta", "background.bfile")
                yield [[seq, bgfile, motif], outfile]

            else:
                yield [[seq, motif], outfile]

                
@follows(prepSequences, prepMotifs, mkdir("fimo.dir"))
@files(generateFimo)
def fimo(infiles, outfile):
    '''Run FIMO'''

    if len(infiles) == 3:
        sequences, background, motifs = infiles
        opts = '''--bgfile %(background)s''' % locals()
        bgfile = ""

    else:
        sequences, motifs = infiles
        bgfile = PARAMS["fimo_background"]
        
    if bgfile == "motif-file":
        opts = '''--bgfile motif-file'''
        
    elif bgfile == "none":
        opts = ''' '''

    else:
        opts = opts

    pval = PARAMS["fimo_pvalue"]
    
    outdir = outfile.replace(".fimo.log", "")
    
    statement = '''fimo
                   %(opts)s
                   --oc %(outdir)s
                   --thresh %(pval)s
                   %(motifs)s                   
                   %(sequences)s
                   &> %(outfile)s ''' 

    P.run()


@transform(fimo,
           regex(r"(.*).fimo.log"),
           r"\1/fimo.load")
def loadFimo(infile, outfile):
    '''load fimo results from tsv'''

    job_memory = "4G"
    fimo_result = infile.replace(".fimo.log", "/fimo.txt")

    # escape clause if fimo fails to find motifs
    if len(pd.read_csv(fimo_result, sep="\t"))==0:
        statement = '''echo "file %(fimo_result)s empty" ''' % locals()

    else:
        tablename = '_'.join([outfile.split("/")[1], "fimo_results"]).replace(".", "_")
        opts='-H "pattern_name,sequence_name,start,stop,strand,score,p_value,q_value,matched_sequence" '

        statement = '''grep -v "#" %(fimo_result)s | '''
        statement = statement + P.build_load_statement(tablename, options=opts, retry=True)
        statement = statement + ''' > %(outfile)s'''

        to_cluster = True

    P.run()
    

@follows(loadFimo)
@transform("fimo.dir/*/fimo.load",
           regex(r"(.*).load"),
           [r"\1_summary.txt", r"\1.bed"])
def fimoBed(infile, outfiles):
    '''Make BED file of FIMO motif locations. FIMO filters 
       by p-value. All motif matches past threshold 
       are exported to bed and results files'''

    job_memory = "6G"
    script = PARAMS["pipeline_dir"] + "fimoBED.py"
    db = PARAMS["database"]
    outfiles = ','.join(outfiles)
    
    statement = '''python %(script)s
                     --infile %(infile)s
                     --outfiles '%(outfiles)s'
                     --db %(db)s'''

    print(statement)
    
    P.run()


@follows(fimoBed)
def runFIMO():
    pass


def coverageBedGenerator():
    '''Create jobs to annotate infiles with motif matches'''

    infiles = glob.glob("meme.seq.dir/*.foreground.bed")
    motifs = glob.glob("fimo.dir/*/*.bed")

    if len(infiles)==0 or len(motifs)==0:
        pass
    
    outdir = "motif.coverage.dir/"
    
    db_motifs = []
    custom_motifs = []
    
    for motif in motifs:
        if "db_motifs" in motif:
            db_motifs.append(motif)
        else:
            custom_motifs.append(motif)

    if db_motifs:
        db_motifs = [x for x in db_motifs if "fimo.bed" not in x ] # drop mixed motif file

    # match infiles to motif beds
    for mlist in [db_motifs, custom_motifs]:
        for bed in infiles:
            interval_name = os.path.basename(bed).replace(".foreground.bed", "")

            for anno in mlist:
                sequence_name, motif_dir = anno.split("/")[1].split(".")

                # match custom motifs to infiles
                if motif_dir != "db_motifs":
                    outfile = outdir + interval_name + "." + motif_dir + ".coverage.bed.gz"
                    
                else:
                    # db_motifs
                    motif_name = os.path.basename(anno).replace("fimo_", "").replace(".bed", "")
                    motif_name = motif_name.replace("(", "").replace(")", "") # hack, remove or escape special chars
                    outfile = outdir + interval_name + "." + motif_name + ".coverage.bed.gz"
                    
                if interval_name == sequence_name:

                    yield [ [bed, anno], outfile]
                                  

# it would be more space efficient to merge these 2 tasks and delete intermediate files
@follows(runFIMO, mkdir("motif.coverage.dir"))
@files(coverageBedGenerator)
def coverageBed(infiles, outfile):
    '''Calculate per base coverage of peaks by motif files'''

    bed, motif = infiles

    statement = '''coverageBed 
                     -d 
                     -a %(bed)s                      
                     -b %(motif)s 
                   | gzip - > %(outfile)s '''

    print(statement)

    P.run()
    

@transform(coverageBed,
           regex(r"(.*).bed.gz"),
           r"\1.bed.prep.gz")
def prepareBeds(infile, outfile):
    '''Prepare BEDs for plotting'''

    # This used to be in plotMotifEnrichment.py but was to slow when implemented in pandas
    # Prepare beds for plotting here instead
    
    # 1) position in peak changed to peak centre +/- n b.p. (rather than peak start)
    # 2) subset on window to plot (peak centre +/- n b.p. )

    tmp_dir = "$SCRATCH_DIR"
    window = PARAMS["fimo_plot_window"]

    statement = '''tmp=`mktemp -p %(tmp_dir)s`; checkpoint;
                   awk 'BEGIN {OFS="\\t"} 
                     {pwidth=$3-$2}
                     {pcentre=pwidth/2}
                     {if ($5 >= pcentre) print $1,$2,$3,$4,$5-pcentre,$6;
                     else print $1,$2,$3,$4,"-"pcentre-$5,$6}'
                     <( zcat %(infile)s )
                     > $tmp ; checkpoint;
                   awk 'BEGIN {OFS="\\t"}
                     {if ($5 <= %(window)s && $5 >= -%(window)s ) print $0}' 
                     $tmp |
                   grep -v "chrM" - |
                   gzip - > %(outfile)s'''

    # problem with erroneous intervals on chrM not of uniform length
    # these should be removed as most likely artifacts
    
    print(statement)

    P.run()

    
@transform(prepareBeds,
           regex(r"(.*).bed.prep.gz"),
           r"\1.png")
def plotMotifEnrichment(infile, outfile):
    '''Normalise coverage profiles & plot motif enrichment'''

    job_memory = "35G"
    
    region_motif = os.path.basename(infile).split(".")
    region = region_motif[0]
    motif = region_motif[1]
    
    bin_size = PARAMS["fimo_bins"]
    script = PARAMS["pipeline_dir"] + "plotMotifEnrichment.py"
    normalisation = PARAMS["fimo_norm"]
    
    statement = '''python %(script)s
                     --infile %(infile)s
                     --outfile %(outfile)s
                     --motif %(motif)s
                     --region %(region)s
                     --norm %(normalisation)s
                     --gzip True
                     --fast True 
                     --bins %(bin_size)s'''

    P.run()


def plotMotifEnrichmentAllGenerator():

    motif_cov = glob.glob("motif.coverage.dir/*.bed.prep.gz") 
    outdir = "motif.coverage.dir/"

    if len(motif_cov)==0:
        pass
    
    peaks = []
    for m in motif_cov:
        tf = os.path.basename(m).split(".")[0]
        peaks.append(tf)    
    peaks = list(set(peaks))

    for p in peaks:
        motifs = [x for x in motif_cov if p == os.path.basename(x).split(".")[0] ]
        outfile = outdir + p + ".ALL_motifs.coverage.png"

        print([motifs, outfile])


@follows(prepareBeds)
@files(plotMotifEnrichmentAllGenerator)
def plotMotifEnrichmentAll(infiles, outfile):
    '''Normalise coverage profiles & plot motif enrichment
       *** all motifs on same plot ***'''

    region = os.path.basename(infiles[0]).replace(".coverage.bed.prep.gz", "").split(".")[0]
    tmp_dir = "$SCRATCH_DIR"
    infiles = ' '.join(infiles)

    bin_size = PARAMS["fimo_bins"]
    script = PARAMS["pipeline_dir"] + "plotMotifEnrichment.py"
    normalisation = PARAMS["fimo_norm"]
    
    statement = '''python %(script)s
                     --infile %(infiles)s
                     --outfile %(outfile)s
                     --region %(region)s 
                     --norm %(normalisation)s
                     --gzip True
                     --fast True
                     --bins %(bin_size)s'''

    P.run()
    

# @transform(coverageBed,
#            regex(r"(.*).bed.gz"),
#            r"\1.bw")
# def bedToBW(infile, outfile):
#     '''convert bed coverage track -> BDG -> BW'''

#     chrom_sizes = PARAMS["annotations_chrom_sizes"]
#     tmp_dir = "$SCRATCH_DIR"

#     # chrM causing errors, many intervals larger than annotated chrom size
#     # hack = remove chrM peaks
    
#     statement = '''tmp=`mktemp -p %(tmp_dir)s`; checkpoint;
#                    awk 
#                      'BEGIN {OFS="\\t"} 
#                      {X=$3+$5}
#                      {print $1,X-1,X,"-",$6}'
#                      <( zcat %(infile)s ) |
#                    grep -v "chrM" - |
#                    sort -k1,1 -k2,2n - |
#                    mergeBed -c 5 -o mean -d -1 -i - 
#                      > $tmp; checkpoint;
#                    bedGraphToBigWig
#                      $tmp
#                      %(chrom_sizes)s
#                      %(outfile)s; checkpoint;
#                    rm $tmp '''

#     P.run()

    
# ---------------------------------------------------
# Generic pipeline tasks
@follows(prepSequences, prepMotifs, runFIMO, plotMotifEnrichment)
def full():
    pass


def main(argv=None):
    if argv is None:
        argv = sys.argv
    P.main(argv)


if __name__ == "__main__":
    sys.exit(P.main(sys.argv))    
